[
  {
    "path": "posts/2022-05-30-post7/",
    "title": "Cumhurbaşkanlığı Hükümet Sistemi Yapısal Kırılmaya Yol Açtı mı?",
    "description": "Ekonomik ve finansal değişkenlerin yapısal kırılma analizi.",
    "author": [
      {
        "name": "A. Uraz Akgül",
        "url": {}
      }
    ],
    "date": "2022-05-30",
    "categories": [
      "Economics",
      "Finance"
    ],
    "contents": "\r\nCumhurbaşkanlığı hükümet sistemi, 16 Nisan 2017 referandumu ile kabul\r\nedildi ve 9 Temmuz 2018 tarihinden itibaren de uygulanmaya başlandı. 24\r\nHaziran 2018’de de genel seçimler ile birlikte Cumhurbaşkanlığı seçimi\r\nyapıldı ve sistemin ilk lideri Erdoğan oldu.\r\nBu yazıda inceleyeceğimiz konu, Cumhurbaşkanlığı Hükümet Sistemi’nin\r\nekonomik ve finansal değişkenlerde yapısal kırılmaya yol açıp\r\naçmadığıdır.\r\nYapısal kırılma analizi için enflasyon, kur ve faiz verilerini\r\nseçtim. TCMB/EVDS’den aldığım verilere (post7.xlsx) GitHub\r\nhesabımdan ulaşabilirsiniz.\r\nFrekansları aylık ve çeyreklik bazda alıp yapısal kırılmayı bu\r\nşekilde inceleyeceğiz. Veri aralığı ise 2015-2022 yılları arasını\r\nkapsayacak.\r\nAylık olan frekansları çeyreklik olarak da incelemek isteme sebebim,\r\nbir olayın etkisi hemen o ay değil; içinde bulunduğu çeyrek içinde\r\nbaşladıysa kaçırmamaktır. 2015-2022 yıllarını seçme sebebim ise 2018\r\nyılının öncesi ve sonrasına zamanı yaklaşık olarak eşit dağıtmaktır.\r\nÇalışmada, serilerde birden fazla yapısal kırılma olduğu zaman\r\nkullanılabilen ve bu kırılmaları endojen (içsel) olarak kabul eden\r\nBai-Perron yöntemi kullanılmıştır. Bai-Perron (1998,2003), en küçük\r\nkareler yöntemi ile tahmin edilen regresyon modelinde bilinmeyen kırılma\r\nzamanlarını belirlemek amacıyla çoklu kırılmaların tespitine yönelik\r\ntest geliştirmişlerdir.\r\nBilinmeyen tarihlerdeki m adet kırılma (m+1 rejim) için oluşturulan\r\nçoklu regresyon modeli şöyledir:\r\n\\(y_t = x_t'\\beta + z_t'\\delta_1 +\r\n\\epsilon_t; t = 1,...,T_1\\)\r\n\\(y_t = x_t'\\beta + z_t'\\delta_2 +\r\n\\epsilon_t; t = T_1 + 1,...,T_2\\)\r\n. . .\r\n\\(y_t = x_t'\\beta + z_t'\\delta_j +\r\n\\epsilon_t; t = T_{j-1} + 1,...T_j; j = 1,...,m\\)\r\nSon yazdığımız denklemde;\r\n\\(x_t'\\) ve \\(z_t'\\) sırasıyla px1 ve qx1 boyutlu\r\nbağımsız değişkenler vektörü,\r\n\\(\\beta\\) ve \\(\\delta_j\\) katsayılar vektörü,\r\n\\(\\epsilon_t\\) saf hata terimi,\r\n\\(T_0 = 0\\) ve \\(T_{m+1} = T\\) olmak üzere, \\(T_1,T_2,...,T_m\\) bilinmeyen kırılma\r\nnoktalarıdır.\r\nBai-Perron testinin temel amacı, T sayıda gözlem, \\(y_t\\), \\(x_t'\\) ve \\(z_t'\\)’nin değerlerinin bilindiği\r\nvarsayımı altında, bilinmeyen regresyon parametreleri (\\(\\beta,\\delta_1,...,\\delta_m\\)) ve kırılma\r\ntarihlerinin (\\(T_1,T_2,...,T_m\\))\r\nbirlikte tahmin edilmesidir.\r\n\r\n\r\n\r\nEnflasyon\r\n\r\n\r\n\r\n=============================\r\n                  (Intercept)\r\n-----------------------------\r\n2015(1) - 2018(5)    9.094   \r\n2018(6) - 2021(3)   15.302   \r\n2021(4) - 2022(4)   32.352   \r\n-----------------------------\r\n\r\nAylık frekansta 2 tane kırılmanın olduğunu görüyoruz. İlk kırılma\r\n2018 yılının Mayıs ayına denk geliyor. Haziran ve Temmuz 2018’in\r\nsırasıyla seçimin yapıldığı ve sistemin uygulanmaya başlandığı aylar\r\nolduğunu biliyoruz. Sistem içerisinde bir kırılma da Mart 2021’de\r\nyaşanmış. Bu, piyasalara verdiği güven ile bilinen TCMB eski başkanı\r\nNaci Ağbal’ın görevden alındığı dönemdir. Yazının ilerleyen bölümlerinde\r\nfaizi de inceleyeceğiz. Şimdi o faizi alıp enflasyon ile bir araya\r\ngetirip bir bakalım. Çünkü, faiz sebep enflasyon sonuçtur\r\nısrarının bedelini ödemeye devam ettiğimizin resmi olacak.\r\n\r\n\r\n\r\n\r\n\r\n\r\n=============================\r\n                  (Intercept)\r\n-----------------------------\r\n2015(1) - 2021(2)   12.107   \r\n2021(3) - 2022(2)   42.438   \r\n-----------------------------\r\n\r\nÇeyreklik frekansta sadece 1 kırılma verdi o da 2021 yılının 2.\r\nçeyreğine ait.\r\nÜzerinde durduğumuz enflasyon-faiz serilerindeki kırılmayı çeyreklik\r\nolarak biraz daha fazla görebiliriz.\r\n\r\n\r\n\r\nFaiz\r\n\r\n\r\n\r\n===============================\r\n                    (Intercept)\r\n-------------------------------\r\n2015(1) - 2017(2)      8.488   \r\n2017(3) - 2018(6)     12.598   \r\n2018(7) - 2019(9)     22.383   \r\n2019(10) - 2020(10)   10.650   \r\n2020(11) - 2022(4)    16.628   \r\n-------------------------------\r\n\r\nAylık frekansta 4 tane kırılmanın olduğunu görüyoruz. Sistemle\r\nberaber ilk kırılma 2018 yılının Haziran ayında yaşanmış ve bu\r\nkırılmadan sonra 2 kırılma daha yaşanmış. Erdoğan’ın 24 Haziran öncesi\r\nsöylediği, 24’ünde siz bu kardeşinize yetkiyi verin, ondan sonra bu\r\nfaizle, şunla bunla nasıl uğraşılır göreceksiniz sözünün tabloya\r\nyansımış halini görüyoruz adeta.\r\n\r\n\r\n\r\n=============================\r\n                  (Intercept)\r\n-----------------------------\r\n2015(1) - 2017(1)    8.580   \r\n2017(2) - 2018(2)   12.706   \r\n2018(3) - 2019(3)   22.383   \r\n2019(4) - 2020(3)   10.522   \r\n2020(4) - 2022(2)   16.166   \r\n-----------------------------\r\n\r\nÇeyreklik frekansta sistem ile beraber 3 kırılma görüyoruz. İlki\r\nseçimin de içinde bulunduğu 2. çeyrek.\r\nKur\r\n\r\n\r\n\r\n=============================\r\n                  (Intercept)\r\n-----------------------------\r\n2015(1) - 2018(4)    3.202   \r\n2018(5) - 2020(2)    5.565   \r\n2020(3) - 2021(3)    7.246   \r\n2021(4) - 2022(4)   10.790   \r\n-----------------------------\r\n\r\nAylık frekansta 3 tane kırılmanın olduğunu görüyoruz. Sistemden önce\r\nkırılma 2018 yılının Nisan ayında yaşanmış ve bu kırılmadan sonra sistem\r\niçerisinde 2 kırılma daha yaşanmış. Kırılmalardan biri yine daha önce\r\nbahsettiğim eski başkan Ağbal’ın görevden alındığı tarihte yaşanmış.\r\n\r\n\r\n\r\n=============================\r\n                  (Intercept)\r\n-----------------------------\r\n2015(1) - 2018(2)    3.265   \r\n2018(3) - 2020(1)    5.700   \r\n2020(2) - 2021(2)    7.532   \r\n2021(3) - 2022(2)   12.046   \r\n-----------------------------\r\n\r\nÇeyreklik frekansta sistemin de içinde bulunduğu 2018 yılının 2.\r\nçeyreğindeki kırılma ile beraber toplamda 3 kırılma yaşanmış.\r\nSon olarak enflasyon, faiz ve kur değişkenlerini endeks\r\nhaline getirelim. Soru: 2011 yılı itibarıyla kaç kırılma\r\nyaşandı?\r\nSerileri önce aşağıdaki gibi normalize edeceğiz.\r\n\\(X_{nor} = \\frac{X - X_{min}}{X_{max} -\r\nX_{min}}\\)\r\nArdından da değişken sayısına bölerek bir endeks oluşturacağız.\r\n\\(Endeks =\r\n\\frac{Nor(Enflasyon)+Nor(Faiz)+Nor(Kur)}{3}\\)\r\nFaiz için Ağırlıklı Ortalama Fonlama Maliyeti’ni kullandığımız ve bu\r\nveri de 2011 yılı itibarıyla ulaşılabilir olduğu için 2011/Ocak -\r\n2022/Nisan verilerini kullanacağız.\r\n\r\n\r\n\r\n\r\n\r\n\r\n==============================\r\n                   (Intercept)\r\n------------------------------\r\n2011(1) - 2016(9)     0.082   \r\n2016(10) - 2018(5)    0.198   \r\n2018(6) - 2020(8)     0.382   \r\n2020(9) - 2022(4)     0.508   \r\n------------------------------\r\n\r\n2011 yılı itbarıyla aylık (ve çeyreklik) frekansta 3 kırılmanın\r\nyaşandığını görüyoruz. Bunların ilki sistem öncesi, biri sisteme çok\r\nyakın ve biri sistem sonrası. Sistem ile beraber oluşturulan endeksin\r\nyukarı doğru tırmanışı dikkat çekici. Her ne kadar sonrasında bir\r\ntoparlanma sürecine girse de atılan yanlış adımların etkisi çok ciddi\r\nolmuş ki olmaya da devam ediyor.\r\n\r\n\r\n\r\n=============================\r\n                  (Intercept)\r\n-----------------------------\r\n2011(1) - 2016(4)    0.084   \r\n2017(1) - 2018(2)    0.220   \r\n2018(3) - 2020(4)    0.378   \r\n2021(1) - 2022(2)    0.580   \r\n-----------------------------\r\n\r\nÇalışmanın R kodlarına aşağıdan ulaşılabilir.\r\n\r\n\r\noptions(scipen = 999)\r\n\r\nlibrary(strucchange) # yapısal kırılma\r\nlibrary(tidyverse)\r\nlibrary(lubridate)\r\nlibrary(stargazer)\r\n\r\ndf_aylik <- readxl::read_excel(\"data.xlsx\") %>% \r\n  mutate(tarih = as.Date(paste0(tarih,\"-\",1))) %>% \r\n  na.omit() %>% \r\n  filter(tarih >= as.Date(\"2015-01-01\"))\r\n\r\n# enflasyon\r\n\r\nenf_aylik <- df_aylik %>% \r\n  select(tarih,enflasyon) %>% \r\n  mutate(t = seq(1,nrow(.),1))\r\n\r\nenf_ceyreklik <- enf_aylik %>% \r\n  mutate(tarih = as.Date(paste0(year(tarih),\"-\",quarter(tarih),\"-\",1))) %>% \r\n  group_by(tarih) %>% \r\n  summarise(enflasyon = mean(enflasyon)) %>% \r\n  ungroup() %>% \r\n  mutate(t = seq(1,nrow(.),1))\r\n\r\n# faiz\r\n\r\nfaiz_aylik <- df_aylik %>% \r\n  select(tarih,faiz) %>% \r\n  mutate(t = seq(1,nrow(.),1))\r\n\r\nfaiz_ceyreklik <- faiz_aylik %>% \r\n  mutate(tarih = as.Date(paste0(year(tarih),\"-\",quarter(tarih),\"-\",1))) %>% \r\n  group_by(tarih) %>% \r\n  summarise(faiz = mean(faiz)) %>% \r\n  ungroup() %>% \r\n  mutate(t = seq(1,nrow(.),1))\r\n\r\n# kur\r\n\r\nkur_aylik <- df_aylik %>% \r\n  select(tarih,kur) %>% \r\n  mutate(t = seq(1,nrow(.),1))\r\n\r\nkur_ceyreklik <- kur_aylik %>% \r\n  mutate(tarih = as.Date(paste0(year(tarih),\"-\",quarter(tarih),\"-\",1))) %>% \r\n  group_by(tarih) %>% \r\n  summarise(kur = mean(kur)) %>% \r\n  ungroup() %>% \r\n  mutate(t = seq(1,nrow(.),1))\r\n\r\nenf_aylik_ts <- ts(data = enf_aylik$enflasyon,\r\n                   start = c(2015,1),\r\n                   frequency = 12)\r\n\r\nenf_aylik_bps <- breakpoints(enf_aylik_ts~1)\r\n\r\nenf_aylik <- enf_aylik %>% \r\n  mutate(bp = ifelse(t %in% enf_aylik_bps$breakpoints, t, NA))\r\n\r\nggplot(enf_aylik, aes(x = tarih, y = enflasyon)) +\r\n  geom_line() +\r\n  geom_vline(data = enf_aylik %>% na.omit(),\r\n             aes(xintercept = tarih), linetype = \"dashed\") +\r\n  theme_minimal() +\r\n  theme(plot.title = element_text(face = \"bold\", size = 10),\r\n        plot.subtitle = element_text(face = \"italic\", size = 7),\r\n        axis.title = element_blank()) +\r\n  scale_x_date(date_breaks = \"year\", date_labels = \"%Y\") +\r\n  labs(title = \"Enflasyon, Aylık\",\r\n       subtitle = \"2015/Ocak-2022/Nisan\")\r\n\r\nstargazer(coef(enf_aylik_bps), type = \"text\")\r\n\r\nenf_faiz_aylik <- merge(enf_aylik[,c(1,2)], faiz_aylik[,c(1,2)]) %>% \r\n  mutate(t = seq(1,nrow(.),1)) %>% \r\n  pivot_longer(!c(t,tarih), names_to = \"vars\", values_to = \"vals\")\r\n\r\nenf_faiz_tarih <- enf_faiz_aylik %>% \r\n  filter(t == enf_aylik_bps$breakpoints[2]) %>% \r\n  pull(tarih)\r\n\r\nggplot(enf_faiz_aylik, aes(x = tarih, y = vals, group = vars, color = vars)) +\r\n  geom_line() +\r\n  geom_vline(xintercept = enf_faiz_tarih, linetype = \"dashed\") +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        plot.title = element_text(face = \"bold\"),\r\n        legend.position = \"top\",\r\n        legend.title = element_blank()) +\r\n  scale_color_manual(values = c(\"red\",\"blue\")) +\r\n  scale_x_date(date_breaks = \"year\", date_labels = \"%Y\") +\r\n  labs(title = \"Aylık\")\r\n\r\nenf_ceyreklik_ts <- ts(data = enf_ceyreklik$enflasyon,\r\n                       start = c(2015,1),\r\n                       frequency = 4)\r\n\r\nenf_ceyreklik_bps <- breakpoints(enf_ceyreklik_ts~1)\r\n\r\nenf_ceyreklik <- enf_ceyreklik %>% \r\n  mutate(bp = ifelse(t %in% enf_ceyreklik_bps$breakpoints, t, NA))\r\n\r\nggplot(enf_ceyreklik, aes(x = tarih, y = enflasyon)) +\r\n  geom_line() +\r\n  geom_vline(data = enf_ceyreklik %>% na.omit(),\r\n             aes(xintercept = tarih), linetype = \"dashed\") +\r\n  theme_minimal() +\r\n  theme(plot.title = element_text(face = \"bold\", size = 10),\r\n        plot.subtitle = element_text(face = \"italic\", size = 7),\r\n        plot.caption = element_text(face = \"italic\", size = 7),\r\n        axis.title = element_blank()) +\r\n  scale_x_date(date_breaks = \"year\", date_labels = \"%Y\") +\r\n  labs(title = \"Enflasyon, Çeyreklik*\",\r\n       subtitle = \"2015/Q1-2022/Q2**\",\r\n       caption = \"*Üçer aylık ortalamalardır.\\n**Henüz tamamlanmamıştır.\")\r\n\r\nstargazer(coef(enf_ceyreklik_bps), type = \"text\")\r\n\r\nenf_faiz_ceyreklik <- merge(enf_ceyreklik[,c(1,2)], faiz_ceyreklik[,c(1,2)]) %>% \r\n  mutate(t = seq(1,nrow(.),1)) %>% \r\n  pivot_longer(!c(t,tarih), names_to = \"vars\", values_to = \"vals\")\r\n\r\nenf_faiz_tarih2 <- enf_faiz_ceyreklik %>% \r\n  filter(t == enf_ceyreklik_bps$breakpoints[1]) %>% \r\n  pull(tarih)\r\n\r\nggplot(enf_faiz_ceyreklik, aes(x = tarih, y = vals, group = vars, color = vars)) +\r\n  geom_line() +\r\n  geom_vline(xintercept = enf_faiz_tarih2, linetype = \"dashed\") +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        plot.title = element_text(face = \"bold\"),\r\n        legend.position = \"top\",\r\n        legend.title = element_blank()) +\r\n  scale_color_manual(values = c(\"red\",\"blue\")) +\r\n  scale_x_date(date_breaks = \"year\", date_labels = \"%Y\") +\r\n  labs(title = \"Çeyreklik\")\r\n\r\nfaiz_aylik_ts <- ts(data = faiz_aylik$faiz,\r\n                    start = c(2015,1),\r\n                    frequency = 12)\r\n\r\nfaiz_aylik_bps <- breakpoints(faiz_aylik_ts~1)\r\n\r\nfaiz_aylik <- faiz_aylik %>% \r\n  mutate(bp = ifelse(t %in% faiz_aylik_bps$breakpoints, t, NA))\r\n\r\nggplot(faiz_aylik, aes(x = tarih, y = faiz)) +\r\n  geom_line() +\r\n  geom_vline(data = faiz_aylik %>% na.omit(),\r\n             aes(xintercept = tarih), linetype = \"dashed\") +\r\n  theme_minimal() +\r\n  theme(plot.title = element_text(face = \"bold\", size = 10),\r\n        plot.subtitle = element_text(face = \"italic\", size = 7),\r\n        axis.title = element_blank()) +\r\n  scale_x_date(date_breaks = \"year\", date_labels = \"%Y\") +\r\n  labs(title = \"Faiz, Aylık\",\r\n       subtitle = \"2015/Ocak-2022/Nisan\")\r\n\r\nstargazer(coef(faiz_aylik_bps), type = \"text\")\r\n\r\nfaiz_ceyreklik_ts <- ts(data = faiz_ceyreklik$faiz,\r\n                        start = c(2015,1),\r\n                        frequency = 4)\r\n\r\nfaiz_ceyreklik_bps <- breakpoints(faiz_ceyreklik_ts~1)\r\n\r\nfaiz_ceyreklik <- faiz_ceyreklik %>% \r\n  mutate(bp = ifelse(t %in% faiz_ceyreklik_bps$breakpoints, t, NA))\r\n\r\nggplot(faiz_ceyreklik, aes(x = tarih, y = faiz)) +\r\n  geom_line() +\r\n  geom_vline(data = faiz_ceyreklik %>% na.omit(),\r\n             aes(xintercept = tarih), linetype = \"dashed\") +\r\n  theme_minimal() +\r\n  theme(plot.title = element_text(face = \"bold\", size = 10),\r\n        plot.subtitle = element_text(face = \"italic\", size = 7),\r\n        plot.caption = element_text(face = \"italic\", size = 7),\r\n        axis.title = element_blank()) +\r\n  scale_x_date(date_breaks = \"year\", date_labels = \"%Y\") +\r\n  labs(title = \"Faiz, Çeyreklik*\",\r\n       subtitle = \"2015/Q1-2022/Q2**\",\r\n       caption = \"*Üçer aylık ortalamalardır.\\n**Henüz tamamlanmamıştır.\")\r\n\r\nstargazer(coef(faiz_ceyreklik_bps), type = \"text\")\r\n\r\nkur_aylik_ts <- ts(data = kur_aylik$kur,\r\n                   start = c(2015,1),\r\n                   frequency = 12)\r\n\r\nkur_aylik_bps <- breakpoints(kur_aylik_ts~1)\r\n\r\nkur_aylik <- kur_aylik %>% \r\n  mutate(bp = ifelse(t %in% kur_aylik_bps$breakpoints, t, NA))\r\n\r\nggplot(kur_aylik, aes(x = tarih, y = kur)) +\r\n  geom_line() +\r\n  geom_vline(data = kur_aylik %>% na.omit(),\r\n             aes(xintercept = tarih), linetype = \"dashed\") +\r\n  theme_minimal() +\r\n  theme(plot.title = element_text(face = \"bold\", size = 10),\r\n        plot.subtitle = element_text(face = \"italic\", size = 7),\r\n        axis.title = element_blank()) +\r\n  scale_x_date(date_breaks = \"year\", date_labels = \"%Y\") +\r\n  labs(title = \"Kur, Aylık\",\r\n       subtitle = \"2015/Ocak-2022/Nisan\")\r\n\r\nstargazer(coef(kur_aylik_bps), type = \"text\")\r\n\r\nkur_ceyreklik_ts <- ts(data = kur_ceyreklik$kur,\r\n                       start = c(2015,1),\r\n                       frequency = 4)\r\n\r\nkur_ceyreklik_bps <- breakpoints(kur_ceyreklik_ts~1)\r\n\r\nkur_ceyreklik <- kur_ceyreklik %>% \r\n  mutate(bp = ifelse(t %in% kur_ceyreklik_bps$breakpoints, t, NA))\r\n\r\nggplot(kur_ceyreklik, aes(x = tarih, y = kur)) +\r\n  geom_line() +\r\n  geom_vline(data = kur_ceyreklik %>% na.omit(),\r\n             aes(xintercept = tarih), linetype = \"dashed\") +\r\n  theme_minimal() +\r\n  theme(plot.title = element_text(face = \"bold\", size = 10),\r\n        plot.subtitle = element_text(face = \"italic\", size = 7),\r\n        plot.caption = element_text(face = \"italic\", size = 7),\r\n        axis.title = element_blank()) +\r\n  scale_x_date(date_breaks = \"year\", date_labels = \"%Y\") +\r\n  labs(title = \"Kur, Çeyreklik*\",\r\n       subtitle = \"2015/Q1-2022/Q2**\",\r\n       caption = \"*Üçer aylık ortalamalardır.\\n**Henüz tamamlanmamıştır.\")\r\n\r\nstargazer(coef(kur_ceyreklik_bps), type = \"text\")\r\n\r\ndf_aylik2 <- readxl::read_excel(\"data.xlsx\") %>% \r\n  mutate(tarih = as.Date(paste0(tarih,\"-\",1))) %>% \r\n  na.omit()\r\n\r\nnormalize <- function(x){\r\n  \r\n  return((x - min(x)) / (max(x) - min(x)))\r\n  \r\n}\r\n\r\ndf_endeks <- df_aylik2 %>% \r\n  mutate_at(vars(-tarih), function(x) normalize(x)) %>% \r\n  mutate(endeks = rowSums(.[,-1])/ncol(.[,-1]),\r\n         t = seq(1,nrow(.),1))\r\n\r\nendeks_aylik_ts <- ts(data = df_endeks$endeks,\r\n                      start = c(2011,1),\r\n                      frequency = 12)\r\n\r\nendeks_aylik_bps <- breakpoints(endeks_aylik_ts~1)\r\n\r\ndf_endeks <- df_endeks %>% \r\n  mutate(bp = ifelse(t %in% endeks_aylik_bps$breakpoints, t, NA))\r\n\r\nggplot(df_endeks, aes(x = tarih, y = endeks)) +\r\n  geom_line() +\r\n  geom_vline(data = df_endeks %>% na.omit(),\r\n             aes(xintercept = tarih), linetype = \"dashed\") +\r\n  theme_minimal() +\r\n  theme(plot.title = element_text(face = \"bold\", size = 10),\r\n        plot.subtitle = element_text(face = \"italic\", size = 7),\r\n        plot.caption = element_text(face = \"italic\"),\r\n        axis.title = element_blank()) +\r\n  scale_x_date(date_breaks = \"year\", date_labels = \"%Y\") +\r\n  labs(title = \"2011 Yılı İtibarıyla Yapısal Kırılmalar\",\r\n       subtitle = \"2011/Ocak-2022/Nisan\",\r\n       caption = \"*Normalize edilen (Enflasyon+Faiz+Kur)/3\")\r\n\r\nstargazer(coef(endeks_aylik_bps), type = \"text\")\r\n\r\ndf_endeks2 <- df_endeks %>% \r\n  select(1:5) %>% \r\n  mutate(tarih = as.Date(paste0(year(tarih),\"-\",quarter(tarih),\"-\",1))) %>% \r\n  group_by(tarih) %>% \r\n  summarise(endeks = mean(endeks)) %>% \r\n  ungroup() %>% \r\n  mutate(t = seq(1,nrow(.),1))\r\n\r\nendeks_ceyreklik_ts <- ts(data = df_endeks2$endeks,\r\n                          start = c(2011,1),\r\n                          frequency = 4)\r\n\r\nendeks_ceyreklik_bps <- breakpoints(endeks_ceyreklik_ts~1)\r\n\r\ndf_endeks2 <- df_endeks2 %>% \r\n  mutate(bp = ifelse(t %in% endeks_ceyreklik_bps$breakpoints, t, NA))\r\n\r\nggplot(df_endeks2, aes(x = tarih, y = endeks)) +\r\n  geom_line() +\r\n  geom_vline(data = df_endeks2 %>% na.omit(),\r\n             aes(xintercept = tarih), linetype = \"dashed\") +\r\n  theme_minimal() +\r\n  theme(plot.title = element_text(face = \"bold\", size = 10),\r\n        plot.subtitle = element_text(face = \"italic\", size = 7),\r\n        plot.caption = element_text(face = \"italic\"),\r\n        axis.title = element_blank()) +\r\n  scale_x_date(date_breaks = \"year\", date_labels = \"%Y\") +\r\n  labs(title = \"2011 Yılı İtibarıyla Yapısal Kırılmalar\",\r\n       subtitle = \"2011/Q1-2022/Q2*\",\r\n       caption = \"*Normalize edilen (Enflasyon+Faiz+Kur)/3\\nHenüz tamamlanmamıştır.\")\r\n\r\nstargazer(coef(endeks_ceyreklik_bps), type = \"text\")\r\n\r\n\r\n\r\nYararlandığım Kaynaklar:\r\nFinansal Ekonometri; N.Ç.Yavuz\r\nCumhurbaşkanlığı\r\nHükûmet Sistemi\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-05-30-post7/post7_files/figure-html5/unnamed-chunk-11-1.png",
    "last_modified": "2022-05-30T18:29:05+03:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-24-post6/",
    "title": "İllerin Seçim Zamanı Tüketici Güven Endeksi ve Enflasyona Olan Duyarlılığı",
    "description": "Tüketici Güven Endeksi ve Enflasyon ile illerin oy oranları arasındaki korelasyon.",
    "author": [
      {
        "name": "A. Uraz Akgül",
        "url": {}
      }
    ],
    "date": "2022-05-24",
    "categories": [
      "Election"
    ],
    "contents": "\r\nOy vermede seçmenleri etkileyen birçok faktör bulunmaktadır ve\r\nliteratürde birçok oy verme modeli bulunmaktadır. Bunlardan biri de\r\nekonomik oy verme modelidir. Siyaset biliminde ekonomik oylama, seçmen\r\ndavranışının seçim anında ülkelerindeki ekonomik koşullardan büyük\r\nölçüde etkilendiğini savunan teorik bir bakış açısıdır.\r\nEkonomik oy verme modelinden yola çıkarak iki tane değişken\r\nbelirledim: Tüketici Güven Endeksi ve Enflasyon. İllerin oy oranlarını\r\nise AKP ile sınırlayıp 2007, 2011, 2015-I, 2015-II ve 2018 genel\r\nseçimlerini dikkate aldım. Gözlem sayısının az oluşundan (N = 5) dolayı\r\nanalizime temkinli yaklaşılması konusunda uyarmalıyım ancak bir miktar\r\nfikir verebileceğini de eklemek istiyorum. Özellikle Tüketici Güven\r\nEndeksi tarafı yakından takip edilmelidir.\r\nTÜİK’ten aldığım verilere (post6_1.xls, post6_2.xls,\r\npost6_3.xls) GitHub\r\nhesabımdan ulaşabilirsiniz. Oy oranları verileri Vikipedi’den web\r\nkazıma yöntemi ile alınmıştır.\r\n\r\n\r\n\r\nTüketici Güven Endeksi\r\n\r\n\r\n\r\nTüketici Güven Endeksi, 2004 yılının Ocak ayından 2022 yılının Mayıs\r\nayına kadar toparlama sürecine girse de aşağı yönlü bir eğilim\r\nsergilemiştir. 0 ile 200 arasında yer alan endeksin 100 üzerinde\r\nolmasının iyimser durumu gösterdiğini baz alırsak 221 ayın sadece\r\n7’sinde iyimser bölgede kalabilmiş. Bu 7 değerin 6’sı 2004, 1’i ise 2006\r\nyılına aittir.\r\nVerilerin olduğu aralıkta ilk genel seçim 22 Temmuz 2007’de oldu ve\r\nendeks Haziran ve Temmuz 2007’de sırasıyla 96.5 ve 97.2 idi. Bugün\r\nendeks 67.6 olmuştur.\r\n\r\n\r\n\r\nEnflasyon\r\n\r\n\r\n\r\nEnflasyon, 2004 yılının Ocak ayından 2022 yılının Nisan ayına kadar\r\nlogaritmik olarak baktığımız zaman eksponansiyel bir artış sergilemiş\r\ndiyebiliriz. İlk ciddi bozulmasını ise 2018 yılında göstermiş. 20% üstü\r\nenflasyonun olduğu 11 ayın 4’ü 2018’e, 1’i 2019’a, 2’si 2021’e ve kalan\r\n4’ü 2022’ye aittir.\r\nVerilerin olduğu aralıkta ilk genel seçim 22 Temmuz 2007’de oldu ve\r\nenflasyon Haziran ve Temmuz 2007’de sırasıyla 8.6% ve 6.9% idi. Bugün\r\nenflasyon 70% olmuştur.\r\n\r\n\r\n\r\nGenel Seçimler AKP Oy Oranı\r\nTürkiye, AKP’nin olduğu 6 genel seçim görmüştür.\r\n3 Kasım 2002\r\n22 Temmuz 2007\r\n12 Haziran 2011\r\n7 Haziran 2015\r\n1 Kasım 2015\r\n24 Haziran 2018\r\nGenel seçimlerde (2002 analizde olmayacağı için hariç) aldıkları oy\r\noranlarının zaman serisi aşağıdaki gibidir.\r\n\r\n\r\n\r\nDeğişkenler ile Oy Oranları Arasındaki İlişki\r\n\r\n\r\n\r\nTüketici Güven Endeksi ve Türkiye Geneli Oy Oranları\r\nKorelasyonu\r\nTürkiye genelinde, Tüketici Güven Endeksi’nin artışı oy oranlarına\r\npozitif; düşüşü ise negatif yansımıştır. Aradaki korelasyon: 90.5%\r\n\r\n\r\n\r\nEnflasyon ve Türkiye Geneli Oy Oranları\r\nKorelasyonu\r\nTürkiye genelinde, Enflasyon artışı oy oranlarına negatif; düşüşü ise\r\npozitif yansımıştır ifadesini aslında tam olarak söyleyemiyoruz. 2018\r\nyılına ait enflasyon oranı bir uç değer olmuştur ve eğimi aşağıya\r\nçekmektedir. Aradaki korelasyon: -45.8%\r\n\r\n\r\n\r\nYukarıdaki inceleme geneli yansıtmaktaydı. İller bazında ilişkiler ve\r\nkorelasyon katsayıları değişkenlik gösterebilir ki konumuz da bununla\r\nilgilidir.\r\nTüketici Güven Endeksi ve İllere Ait Oy Oranları\r\nKorelasyonu\r\n\r\n\r\n\r\nTüketici Güven Endeksi’ne en hassas ilin Erzurum olduğunu\r\nsöyleyebiliriz. Bu ili sırasıyla Eskişehir ve Bingöl takip ediyor. Zayıf\r\nda olsa negatif korelasyon gösteren 3 il ise Rize, Kırklareli ve Edirne.\r\n81 ilin 58’i 50%’den fazla pozitif korelasyonu olan yerlerdir.\r\n\r\n\r\n\r\n90% üstü pozitif korelasyona sahip iller\r\n\r\n\r\n\r\nEnflasyon ve İllere Ait Oy Oranları Korelasyonu\r\n\r\n\r\n\r\nEnflasyona en hassas ilin Yozgat olduğunu söyleyebiliriz. Bu ili\r\nsırasıyla Erzincan ve Kırıkkale takip ediyor. Ne zayıf ne güçlü\r\ndiyebileceğimiz pozitif korelasyon gösteren en yüksek 3 il ise Sinop,\r\nTunceli ve Kırklareli’dir. 81 ilin 19’u 50%’den fazla negatif\r\nkorelasyonu olan yerlerdir.\r\n\r\n\r\n\r\n60% üstü negatif korelasyona sahip iller\r\n\r\n\r\n\r\nTüketici Güven Endeksi ve Enflasyon Oranı Değişkenlerinin Oy\r\nOranlarıyla Olan Korelasyonu\r\n\r\n\r\n\r\n\r\n\r\n\r\nYukarıdaki grafiği, dikey eksenden (enflasyon) aşağıya doğru\r\ngittikçe ve yatay eksenden (tüketici güven endeksi) sağa doğru gittikçe\r\nbu değişkenlere olan hassasiyet artmaktadır şeklinde\r\nokuyabiliriz.\r\nÇalışmanın R kodlarına aşağıdan ulaşılabilir.\r\n\r\n\r\noptions(scipen = 999)\r\n\r\nlibrary(tidyverse)\r\nlibrary(rvest) # web kazıma\r\n\r\ntge1 <- readxl::read_excel(\"tge1.xls\") %>% \r\n  select(1,2) %>% \r\n  slice(5:100) %>% \r\n  rename(\"donem\"=1,\"tge\"=2) %>% \r\n  mutate(donem = seq(as.Date(\"2004-01-01\"),as.Date(\"2011-12-01\"), \"months\"),\r\n         tge = as.numeric(tge))\r\n\r\ntge2 <- readxl::read_excel(\"tge2.xls\") %>% \r\n  select(1,4) %>% \r\n  slice(5:129) %>% \r\n  rename(\"donem\"=1,\"tge\"=2) %>% \r\n  mutate(donem = seq(as.Date(\"2012-01-01\"),as.Date(\"2022-05-01\"), \"months\"),\r\n         tge = as.numeric(tge))\r\n\r\ntge <- rbind(tge1,tge2) %>% \r\n  mutate(tgeLag = lag(tge))\r\n\r\nggplot(tge, aes(x = donem, y = tge)) +\r\n  geom_line() +\r\n  geom_smooth(method = \"loess\", color = \"red\") +\r\n  geom_hline(yintercept = 100) +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        plot.title = element_text(face = \"bold\"),\r\n        plot.subtitle = element_text(face = \"italic\"),\r\n        plot.caption = element_text(face = \"italic\")) +\r\n  labs(title = \"Tüketici Güven Endeksi\",\r\n       subtitle = \"Ocak/2004 - Mayıs/2022\",\r\n       caption = \"Veri: TÜİK\")\r\n\r\nenf <- readxl::read_excel(\"enflasyon.xls\") %>% \r\n  slice(80:98) %>% \r\n  `colnames<-`(c(\"yil\",paste0(\"C\",seq(1,18,1)))) %>% \r\n  pivot_longer(!yil, names_to = \"ay\", values_to = \"enf\") %>% \r\n  na.omit() %>% \r\n  mutate(donem = seq(as.Date(\"2004-01-01\"),as.Date(\"2022-04-01\"), \"months\"),\r\n         enf = as.numeric(enf),\r\n         enfLag = lag(enf)) %>% \r\n  select(donem,enf,enfLag)\r\n\r\nggplot(enf, aes(x = donem, y = log(enf))) +\r\n  geom_line() +\r\n  geom_smooth(method = \"loess\", color = \"red\") +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        plot.title = element_text(face = \"bold\"),\r\n        plot.subtitle = element_text(face = \"italic\"),\r\n        plot.caption = element_text(face = \"italic\")) +\r\n  labs(title = \"Enflasyon (Bir Önceki Yılın Aynı Ayına Göre)\",\r\n       subtitle = \"Ocak/2004 - Nisan/2022\",\r\n       caption = \"Veriler logaritmiktir.\\n Veri: TÜİK\")\r\n\r\nakp <- data.frame(\r\n  t = seq(1,5,1),\r\n  tarih = c(\r\n    as.Date(\"2007-07-22\"),\r\n    as.Date(\"2011-06-12\"),\r\n    as.Date(\"2015-06-07\"),\r\n    as.Date(\"2015-11-01\"),\r\n    as.Date(\"2018-06-24\")\r\n  ),\r\n  oran = c(46.58,49.83,40.87,49.50,42.56)\r\n)\r\n\r\nggplot(akp, aes(x = t, y = oran)) +\r\n  geom_line() +\r\n  geom_point(size = 5) +\r\n  geom_text(aes(label = paste0(tarih,\"\\n\",oran,\"%\")), vjust = -0.5, size = 2) +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        plot.title = element_text(face = \"bold\"),\r\n        plot.caption = element_text(face = \"italic\")) +\r\n  scale_y_continuous(limits = c(0,100)) +\r\n  labs(title = \"Genel Seçimler AKP Oy Oranları\",\r\n       caption = \"Veri: Vikipedi\")\r\n\r\ne1 <- read_html(\"https://tr.wikipedia.org/wiki/2007_T%C3%BCrkiye_genel_se%C3%A7imleri\") %>% \r\n  html_table() %>% \r\n  .[[7]] %>% \r\n  select(1,4) %>% \r\n  rename(\"il\"=1,\"akp\"=2) %>% \r\n  mutate(akp = gsub(\",\",\".\",akp),\r\n         donem = as.Date(\"2007-07-01\"))\r\n\r\ne2 <- read_html(\"https://tr.wikipedia.org/wiki/2011_T%C3%BCrkiye_genel_se%C3%A7imleri\") %>% \r\n  html_table() %>% \r\n  .[[9]] %>% \r\n  select(1,4) %>% \r\n  rename(\"il\"=1,\"akp\"=2) %>% \r\n  mutate(akp = gsub(\",\",\".\",akp),\r\n         donem = as.Date(\"2011-06-01\"))\r\n\r\ne3 <- read_html(\"https://tr.wikipedia.org/wiki/Haziran_2015_T%C3%BCrkiye_genel_se%C3%A7imleri\") %>% \r\n  html_table() %>% \r\n  .[[23]] %>% \r\n  select(1,4) %>% \r\n  rename(\"il\"=1,\"akp\"=2) %>% \r\n  mutate(akp = gsub(\",\",\".\",akp),\r\n         donem = as.Date(\"2015-06-01\"))\r\n\r\ne4 <- read_html(\"https://tr.wikipedia.org/wiki/Kas%C4%B1m_2015_T%C3%BCrkiye_genel_se%C3%A7imleri\") %>% \r\n  html_table() %>% \r\n  .[[19]] %>% \r\n  select(1,5) %>% \r\n  rename(\"il\"=1,\"akp\"=2) %>% \r\n  mutate(akp = gsub(\",\",\".\",akp),\r\n         il = gsub(\"\\\\(toplam)\",\"\",il),\r\n         donem = as.Date(\"2015-11-01\")) %>% \r\n  filter(!grepl(\"\\\\(I)|\\\\(II)|\\\\(III)\",il))\r\n    \r\ne5 <- read_html(\"https://tr.wikipedia.org/wiki/2018_T%C3%BCrkiye_genel_se%C3%A7imleri\") %>% \r\n  html_table() %>% \r\n  .[[21]] %>% \r\n  select(1,5) %>% \r\n  rename(\"il\"=1,\"akp\"=2) %>% \r\n  mutate(akp = gsub(\",\",\".\",akp)) %>% \r\n  mutate(akp = gsub(\",\",\".\",akp),\r\n         il = gsub(\"\\\\(toplam)\",\"\",il),\r\n         donem = as.Date(\"2018-06-01\")) %>% \r\n  filter(!grepl(\"\\\\(I)|\\\\(II)|\\\\(III)\",il))\r\n\r\ne <- rbind(e1,e2,e3,e4,e5) %>% \r\n  mutate(il = str_trim(il),\r\n         akp = as.numeric(akp),\r\n         il = gsub(\" Toplamı| toplamı\",\"\",il))\r\n\r\nmaster <- e %>% \r\n  left_join(tge[,c(1,2)], by = \"donem\") %>% \r\n  left_join(enf[,c(1,2)], by = \"donem\") %>% \r\n  arrange(donem)\r\n\r\nmaster %>% \r\n  filter(il == \"Türkiye\") %>% \r\n  ggplot(aes(x = tge, y = akp)) +\r\n  geom_smooth(method = \"lm\") +\r\n  geom_point(size = 5) +\r\n  geom_text(aes(label = paste0(donem,\"\\n\",akp,\"%\")), vjust = -0.7, size = 2) +\r\n  geom_text(aes(label = round(tge, digits = 1)), vjust = 2.5, size = 2) +\r\n  theme_minimal() +\r\n  labs(x = \"Tüketici Güven Endeksi\",\r\n       y = \"Oy Oranı\")\r\n\r\nmaster %>% \r\n  filter(il == \"Türkiye\") %>% \r\n  ggplot(aes(x = enf, y = akp)) +\r\n  geom_smooth(method = \"lm\") +\r\n  geom_point(size = 5) +\r\n  geom_text(aes(label = paste0(donem,\"\\n\",akp,\"%\")), vjust = -0.7, size = 2) +\r\n  geom_text(aes(label = round(enf, digits = 1)), vjust = 2.5, size = 2) +\r\n  theme_minimal() +\r\n  labs(x = \"Enflasyon\",\r\n       y = \"Oy Oranı\")\r\n\r\ntge_corr_il <- master %>% \r\n  group_by(il) %>% \r\n  summarise(corr = cor(akp,tge)) %>% \r\n  arrange(corr) %>% \r\n  mutate(tip = \"TGE\",\r\n         grup = ifelse(corr > 0, \"pozitif\", \"negatif\"))\r\n\r\nggplot(tge_corr_il, aes(x = reorder(il, corr), y = corr, fill = grup)) +\r\n  geom_col() +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        axis.text.y = element_text(size = 10),\r\n        axis.text.x = element_text(size = 10),\r\n        legend.position = \"none\") +\r\n  scale_fill_manual(values = c(\"red\",\"orange\")) +\r\n  scale_y_continuous(sec.axis = sec_axis(trans=~.*1)) +\r\n  coord_flip()\r\n\r\ncorr90_tge <- tge_corr_il %>% \r\n  arrange(desc(corr)) %>% \r\n  filter(corr > 0.9 & il != \"Türkiye\") %>% \r\n  pull(il)\r\n\r\nmaster %>% \r\n  filter(il %in% corr90_tge) %>% \r\n  ggplot(aes(x = tge, y = akp)) +\r\n  geom_smooth(method = \"lm\") +\r\n  geom_point(size = 2) +\r\n  theme_minimal() +\r\n  labs(x = \"Tüketici Güven Endeksi\",\r\n       y = \"Oy Oranı\") +\r\n  facet_wrap(~il, scales = \"free\")\r\n\r\nenf_corr_il <- master %>% \r\n  group_by(il) %>% \r\n  summarise(corr = cor(akp,enf)) %>% \r\n  arrange(corr) %>% \r\n  mutate(tip = \"ENF\",\r\n         grup = ifelse(corr > 0, \"pozitif\", \"negatif\"))\r\n\r\nggplot(enf_corr_il, aes(x = reorder(il, corr), y = corr, fill = grup)) +\r\n  geom_col() +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        axis.text.y = element_text(size = 10),\r\n        axis.text.x = element_text(size = 10),\r\n        legend.position = \"none\") +\r\n  scale_fill_manual(values = c(\"red\",\"orange\")) +\r\n  scale_y_continuous(sec.axis = sec_axis(trans=~.*1)) +\r\n  coord_flip()\r\n\r\ncorr60_enf <- enf_corr_il %>% \r\n  arrange(desc(corr)) %>% \r\n  filter(corr < -0.6 & il != \"Türkiye\") %>% \r\n  pull(il)\r\n\r\nmaster %>% \r\n  filter(il %in% corr60_enf) %>% \r\n  ggplot(aes(x = enf, y = akp)) +\r\n  geom_smooth(method = \"lm\") +\r\n  geom_point(size = 2) +\r\n  theme_minimal() +\r\n  labs(x = \"Enflasyon\",\r\n       y = \"Oy Oranı\") +\r\n  facet_wrap(~il, scales = \"free\")\r\n\r\ncorr_il <- rbind(tge_corr_il,enf_corr_il) %>% \r\n  select(-grup) %>% \r\n  pivot_wider(names_from = \"tip\", values_from = \"corr\")\r\n\r\ntr_enf <- corr_il %>% \r\n  filter(il == \"Türkiye\") %>% \r\n  pull(ENF)\r\n\r\ntr_tge <- corr_il %>% \r\n  filter(il == \"Türkiye\") %>% \r\n  pull(TGE)\r\n\r\nggplot(corr_il, aes(x = TGE, y = ENF)) +\r\n  geom_point(alpha = .1) +\r\n  geom_vline(xintercept = tr_tge, linetype = \"dashed\") +\r\n  geom_hline(yintercept = tr_enf, linetype = \"dashed\") +\r\n  geom_vline(xintercept = 0) +\r\n  geom_hline(yintercept = 0) +\r\n  ggrepel::geom_text_repel(data = corr_il %>% filter(il != \"Türkiye\"),\r\n                           aes(label = il), size = 5) +\r\n  ggrepel::geom_label_repel(data = corr_il %>% filter(il == \"Türkiye\"),\r\n                            aes(label = il), fill = \"red\",\r\n                            size = 5, alpha = .5, color = \"white\") +\r\n  theme_minimal() +\r\n  theme(plot.title = element_text(face = \"bold\", hjust = 0.5),\r\n        plot.subtitle = element_text(face = \"italic\"),\r\n        plot.caption = element_text(face = \"italic\"),\r\n        axis.text = element_text(size = 15),\r\n        axis.title = element_text(size = 15)) +\r\n  labs(title = \"İllere Göre Enflasyon ile Tüketici Güven Endeksinin \r\n       AKP Oy Oranıyla Korelasyonu\",\r\n       caption = \"Türkiye Genel Seçimleri \r\n       (2007,2011,2015-I,2015-II,2018) oy oranlarıdır.\\n\r\n       Veriler seçimden önceki aya aittir.\",\r\n       x = \"Tüketici Güven Endeksi Korelasyonu\",\r\n       y = \"Enflasyon Korelasyonu\")\r\n\r\n\r\n\r\nYararlandığım Kaynaklar:\r\nEconomic\r\nvoting\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-05-24-post6/post6_files/figure-html5/unnamed-chunk-17-1.png",
    "last_modified": "2022-05-24T22:22:20+03:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-22-post4/",
    "title": "Geometric Brownian Motion'ı Kümeleme Algoritmasıyla Kullanmak: USDTRY Simülasyon Uygulaması",
    "description": "Simüle edilmiş değerleri kümeleme algoritmasıyla kullanmak performansı iyileştirebilir.",
    "author": [
      {
        "name": "A. Uraz Akgül",
        "url": {}
      }
    ],
    "date": "2022-05-22",
    "categories": [
      "Finance",
      "Machine Learning"
    ],
    "contents": "\r\nBrownian hareketi (Brownian motion), toz parçacıkları gibi büyük\r\nparçacıkların akışkan içerisinde sıvı ya da gaz molekülleri gibi daha\r\nküçük parçacıklarla çarpışması sonucu oluşan rastlantısal harekettir.\r\nBrown hareketi literatürde Wiener süreci olarak da bilinmektedir.\r\nBrownian hareket sürecinin en basit özel durumu standart Brownian\r\nhareket sürecidir.\r\nYukarıda bahsedilen standart Brownian hareket süreci negatif değerler\r\nde alabildiği için uygulamamıza uymayacaktır. Bu noktada devreye\r\ngeometrik Brownian hareket süreci giriyor. Bu süreçte getiriler\r\nlog-normal dağılımlı olduğu için negatif durum ortadan kaldırılıyor.\r\nBunun yanında log-normal dağılım ile kalın kuyruk durumu ve çarpıklık\r\ndikkate alınmış oluyor.\r\nGeometrik Brownian hareket sürecine uyan bir finansal varlığın\r\nfiyatındaki değişim özellikle finansal modellemede \\(dS_t = \\mu S_t d_t + \\sigma S_t dW_t\\)\r\n(stokastik diferansiyel denklem) olarak ifade edilmektedir. Bu denklem\r\naşağıdaki gibi yeniden yazılabilir:\r\n\\(dlogS_t = (\\mu - \\frac{\\sigma^2}{2})dt +\r\n\\sigma dW_t\\)\r\n\\(dt\\) zaman aralığında değişim olan\r\n\\(dW_t = \\epsilon \\sqrt{dt}\\)’dir.\r\nBurada, \\(W_t\\)’deki değişme miktarı\r\nepsilon ile geçen sürenin karekökünün çarpımı; \\(\\epsilon \\sim N(0,1)\\)’dir ve \\(\\epsilon\\) ortalaması 0, standart sapması 1\r\nolan standart normal dağılım tablosundan üretilen rastsal rakamdır.\r\nSonuç olarak kullanacağımız denklem (Ito Lemma):\r\n\\(S_t = S_0 exp((\\mu -\r\n\\frac{1}{2}\\sigma^2)t + \\sigma W_t)\\) olacaktır.\r\n\\(S_0:\\) başlangıç fiyatı,\r\n\\(\\mu:\\) beklenen getiri (drift,\r\nsürüklenme),\r\n\\(\\sigma:\\) volatilitedir.\r\nUygulamayı şöyle tasarladım:\r\n\\(\\mu\\) ve \\(\\sigma\\)’nın her bir yıl için hesaplanması\r\nve test edilecek yıl için regresyon modeli kullanılarak uygun \\(\\mu\\) ve \\(\\sigma\\) değerinin kullanılması.\r\nHer bir yıl için 1000 adet simüle değerin oluşturulması ve\r\nortalamasının alınması.\r\n2018, 2019, 2020 ve 2021 için test edilmesi.\r\nAlternatif yöntem ile karşılaştırmanın yapılması.\r\nInvesting’ten aldığım verilere (post4.xlsx) GitHub\r\nhesabımdan ulaşabilirsiniz.\r\n\r\n\r\nset.seed(1) # simüle değerlerin her çalıştırmada aynı üretmesi için\r\n\r\nlibrary(tidyverse)\r\nlibrary(lubridate)\r\n\r\n\r\n\r\n\r\n\r\ndf <- readxl::read_excel(\"data.xlsx\")\r\ndf <- df %>% \r\n  mutate(\r\n    logReturn = lag(log(lead(close)/close)),\r\n    date = as.Date(date),\r\n    year = year(date)\r\n  ) %>% \r\n  na.omit()\r\n\r\n\r\n\r\n\r\n\r\n\r\nGeometrik Brownian motion’a ait fonksiyonu oluşturalım.\r\n\r\n\r\ngbmFunc <- function(nsim,t,mu,sigma,S0,nwd){ # kullanıcı tarafından girilecek değerler \r\n  \r\n  gbm <- matrix(ncol = nsim, nrow = t)\r\n  # simülasyon sayısı kadar sütun; gün sayısı kadar satır\r\n  \r\n  for(i in 1:nsim){ # i: initial (başlangıç)\r\n    \r\n    gbm[1,i] <- S0 # gbm matrisinin ilk satırları girilen başlangıç fiyatı olacak\r\n    \r\n    for(d in 2:t){ # d: day (gün); ilk satır belli olduğu için ikinci satırdan başlayacak\r\n      \r\n      epsilon <- rnorm(1) # epsilon ortalaması sıfır ve standart sapması 1 idi\r\n      \r\n      dt <- 1 / nwd # nwd: number of working days (iş günleri sayısı)\r\n      \r\n      gbm[d,i] <- gbm[(d-1),i] * exp((mu - sigma**2 / 2) * dt + sigma * epsilon * sqrt(dt))\r\n      \r\n    }\r\n    \r\n  }\r\n  \r\n  return(gbm)\r\n  \r\n}\r\n\r\n\r\n\r\nTarihsel olarak \\(\\mu\\) ve \\(\\sigma\\) değerlerine bakalım.\r\n\r\n\r\nmusigma_hist <- df %>% \r\n  group_by(year) %>% \r\n  summarise(\r\n    n = n(),\r\n    mu = mean(logReturn),\r\n    sigma = sd(logReturn)*sqrt(n) # iş günü sayısının karekökü ile yıllıklandırma\r\n  ) %>% \r\n  ungroup() %>% \r\n  mutate(t = seq(1,nrow(.),1), .before = n) %>% \r\n  select(-n)\r\n\r\n\r\n\r\n\r\n\r\n\r\nHer yıl için geçmiş 5 seneyi dikkate alarak \\(\\mu\\) ve \\(\\sigma\\) değerlerini tahmin edelim.\r\n\r\n\r\nmusigma_hist$pred_mu <- NA\r\nmusigma_hist$pred_sigma <- NA\r\n\r\ntarget <- 2018:2021\r\n\r\nfor(j in 1:length(target)) {\r\n  m_df <- musigma_hist %>%\r\n    filter(year < target[j] & year >= target[j] - 5) %>%\r\n    mutate(t = seq(1, nrow(.), 1))\r\n  \r\n  model_mu <- lm(mu ~ 0 + t, data = m_df)\r\n  model_sigma <- lm(sigma ~ 0 + t, data = m_df)\r\n  # t: trend\r\n  \r\n  pred_mu <- predict(model_mu, newdata = data.frame(t = nrow(m_df) + 1))\r\n  pred_sigma <- predict(model_sigma, newdata = data.frame(t = nrow(m_df) + 1))\r\n  \r\n  musigma_hist[which(musigma_hist$year == target[j]), ][5] <- as.numeric(pred_mu)\r\n  musigma_hist[which(musigma_hist$year == target[j]), ][6] <- as.numeric(pred_sigma)\r\n  \r\n}\r\n\r\n\r\n\r\nTahmin ettiğimiz değerlerin başarısını RMSE metriği ile ölçeceğiz.\r\nKök Ortalama Kare Hata da diyebileceğimiz Root Mean Square Error, tahmin\r\nhatalarının (residuals) standart sapmasıdır. RMSE için regresyon\r\nçizgisinin etrafındaki yoğunlaşmayı ölçüyor da diyebiliriz.\r\n\\(RMSE =\r\n\\sqrt{\\frac{\\sum_{i=1}^{N}(Tahmin_i-Gerçek_i)^2}{N}}\\)\r\n\r\n\r\nrmse <- function(predicted,actual){\r\n  \r\n  rmse_value <- sqrt(mean((predicted-actual)^2))\r\n  return(rmse_value)\r\n  \r\n}\r\n\r\nrmse_df <- data.frame(\r\n  \"year\" = 2018:2021,\r\n  \"rmse_avg\" = NA\r\n)\r\n\r\n\r\n\r\nTüm yılları hesaplayalım.\r\n\r\n\r\nsim_master <- data.frame()\r\ngbmdf_master <- data.frame()\r\n\r\nfor(k in 1:length(target)){\r\n  \r\n  df_target <- df %>% \r\n    filter(year == target[k])\r\n  \r\n  sim_target <- gbmFunc(nsim = 1000,\r\n                        t = nrow(df_target),\r\n                        mu = as.numeric(musigma_hist[(j+15),5]),\r\n                        sigma = as.numeric(musigma_hist[(j+15),6]),\r\n                        S0 = as.numeric(df_target[1,2]),\r\n                        nwd = nrow(df_target)) %>% \r\n    as.data.frame() %>% \r\n    mutate(\"simAvg\" = rowMeans(.)) %>% \r\n    mutate(rn = 1:nrow(.), .before = V1) %>% \r\n    cbind(df_target[,2]) %>% \r\n    mutate(\"year\" = target[k], .after = rn)\r\n  \r\n  sim_master <- sim_master %>% bind_rows(sim_target)\r\n  \r\n  gbmdf_target <- as.data.frame(sim_target) %>% \r\n    pivot_longer(!c(rn,year), names_to = \"sim\", values_to = \"value\")\r\n  \r\n  gbmdf_master <- gbmdf_master %>% bind_rows(gbmdf_target)\r\n  \r\n  rmse_df$rmse_avg[k] <- rmse(predicted = sim_target$simAvg, actual = sim_target$close)\r\n  \r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n2018-2021 yılları için yaptığımız simülasyonlardan elde ettiğimiz\r\nRMSE değerleri aşağıdaki gibidir.\r\n\r\n\r\nyear\r\n\r\n\r\nrmse_avg\r\n\r\n\r\n2018\r\n\r\n\r\n1.3661915\r\n\r\n\r\n2019\r\n\r\n\r\n0.4085097\r\n\r\n\r\n2020\r\n\r\n\r\n1.3118926\r\n\r\n\r\n2021\r\n\r\n\r\n2.1905821\r\n\r\n\r\nBundan sonra asıl konumuza giriş yapacağız.\r\nTüm simüle değerlerin ortalamasını almak yerine kümeleme\r\nalgoritması kullanıp aynı kümeye düşen simüle değerlerin ortalamasını\r\nalsaydık performans ne olurdu?\r\nKümeleme için aşağıdakileri kullanacağız:\r\nKümeleme algoritması Hierarchical\r\nBağlantı yöntemi Ward\r\nUzaklık ölçütü Euclidean\r\nKümeleme Algoritması Hierarchical\r\n(Hiyerarşik)\r\nHiyerarşik kümeleme yöntemleri, ayrı ayrı ele alınan kümelerin\r\naşamalı olarak birleştirilmesi veya bir ana küme olarak ele alınarak\r\naşamalı olarak alt kümelere ayrılması esasına dayanır.\r\nBağlantı Yöntemi Ward\r\nWard, agglomerative nesting denilen birleştirici kümeleme yöntemidir.\r\nBu yöntemde amaç, bir küme oluşturabilmek için toplam varyanstaki\r\nartışların minimize edilmesidir. Bunun için küme içindeki kareli\r\ntoplamlar kullanılır ve bu değerin minimize edilmesi esas alınır.\r\n\\(ESS = \\sum_{g=1}^{G} \\sum_{i=1}^{n_g}\r\n\\sum_{j=1}^{p} (x_{ij}^g - \\overline{x}_j^g)^2\\)\r\n\\(G:\\) Kümelerin sayısı\r\n\\(n_g:\\) g. küme içindeki gözlem\r\nsayısı\r\n\\(x_{ij}^g:\\) g. küme içindeki i.\r\ngözlemin j. niteliğinin değeri\r\n\\(\\overline{x}_j^g:\\) g. küme\r\niçindeki j niteliğinin ortalaması\r\nUzaklık ölçütü Euclidean (Öklid)\r\nBu uzaklık boyutlu uzayda Pisagor teoreminin bir uygulamasıdır. A\r\nnoktası \\((x_1,y_1)\\); B noktası \\((x_2,y_2)\\) olsun.\r\nA ve B noktaları arasındaki Öklid uzaklığı:\r\n\\(d(A,B) = \\sqrt{(x_1 - x_2)^2 + (y_1 -\r\ny_2)^2}\\)\r\nAlgoritmayı uygulama aşamasına geçebiliriz. Önceki testlerimizden\r\nfarklı olarak burada simülasyonu biraz daha geriden başlatacağız. Çünkü\r\ntest edilecek yıla ait değerlerin henüz gerçekleşmediğini varsayarsak,\r\nönceki yılın bir bölümünü alıp burada gerçekleşen değerleri bir kümeye\r\ndahil etmemiz gerekir. Bunun için de test edilecek yıldan bir önceki\r\nyılın son 100 iş gününü alabiliriz. Bu durumda aşamaları şöyle\r\nsıralayabiliriz: Test edilecek yıldan bir önceki yılın son 100 iş gününü\r\nal, burayı simüle et, simüle değerleri kümelere ayır, 100 gün için\r\ngerçekleşen değerleri bir kümeye dahil et ve buradan seçilen kümeleri\r\nkullanarak test edilecek yılın değerlerini bul. 100 iş gününü seçme\r\nnedenim vade uzadıkça tahmin gücünün zayıflayabileceğini dikkate alarak\r\nçok geriden başlatıp tahmini kötüleştirmemek; bununla beraber, çok da\r\nerken başlatıp zaman serilerini kümelerken kaliteyi düşürmemek.\r\n\r\n\r\nfilter_min <- df %>% \r\n  filter(year %in% 2017:2020) %>% \r\n  group_by(year) %>% \r\n  slice(tail(row_number(), 100)) %>% \r\n  filter(date == min(date)) %>% \r\n  pull(date)\r\n\r\nfilter_max <- df %>% \r\n  filter(year %in% 2018:2021) %>% \r\n  group_by(year) %>% \r\n  filter(date == max(date)) %>% \r\n  pull(date)\r\n\r\nmlsim_master <- data.frame()\r\njoined_clusters_master <- data.frame()\r\n\r\nfor(m in 1:length(target)){\r\n  \r\n  mldf <- df %>% \r\n    filter(date >= filter_min[m] & date <= filter_max[m])\r\n  \r\n  mlsim <- gbmFunc(nsim = 1000,\r\n                   t = nrow(mldf),\r\n                   mu = as.numeric(musigma_hist[(m+15),5]),\r\n                   sigma = as.numeric(musigma_hist[(m+15),6]),\r\n                   S0 = as.numeric(mldf[1,2]),\r\n                   nwd = nrow(mldf)) %>% \r\n    as.data.frame() %>% \r\n    mutate(rn = 1:nrow(.), .before = V1) %>% \r\n    cbind(mldf[,2]) %>% \r\n    mutate(\"year\" = target[m], .after = rn)\r\n  \r\n  mlsim_master <- mlsim_master %>% bind_rows(mlsim)\r\n  \r\n  mlgbm <- t(scale(mlsim[1:100,-c(1,2)])) # son 100 günü kümelemeye dahil etmeliyiz\r\n  mlgbm_dist <- dist(mlgbm, method=\"euclidean\")\r\n  fit <- hclust(mlgbm_dist, method=\"ward.D\")\r\n  \r\n  clustered <- cutree(fit, k=50) # 50 adet küme oluşturulmuştur\r\n  clustered_tidy <- as.data.frame(as.table(clustered)) %>% \r\n    rename(\"sim\"=1,\"cluster\"=2) %>% \r\n    mutate(sim = as.character(sim))\r\n  cluster_x <- clustered_tidy %>% \r\n    filter(sim == \"close\") %>% \r\n    pull(cluster) %>% \r\n    .[[1]]\r\n  \r\n  mldf_2 <- mlsim %>% \r\n    pivot_longer(!c(rn,year), names_to = \"sim\", values_to = \"value\")\r\n  \r\n  joined_clusters <- mldf_2 %>%\r\n    inner_join(clustered_tidy, by = \"sim\") %>% \r\n    filter(cluster == cluster_x) %>% \r\n    select(-cluster) %>% \r\n    pivot_wider(names_from = \"sim\", values_from = \"value\") %>% \r\n    mutate(\"simAvg\" = apply(.[,-c(1,2,ncol(.))], 1, function(x) median(x))) %>% \r\n    # uç değerlerden etkilenmemek için ortalama yerine medyan (ortanca) kullanıldı\r\n    pivot_longer(!c(rn,year), names_to = \"sim\", values_to = \"value\")\r\n  \r\n  joined_clusters_master <- joined_clusters_master %>% bind_rows(joined_clusters)\r\n  \r\n  if(m == length(target)){\r\n    \r\n    rmse_df2 <- joined_clusters_master %>% \r\n      filter(sim %in% c(\"simAvg\",\"close\")) %>% \r\n      pivot_wider(names_from = \"sim\", values_from = \"value\") %>% \r\n      group_by(year) %>% \r\n      summarise(\"rmse_avg_cluster\" = rmse(simAvg,close)) %>% \r\n      ungroup() %>% \r\n      left_join(rmse_df, by = \"year\")\r\n    \r\n  }\r\n  \r\n}\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nyear\r\n\r\n\r\nrmse_avg_cluster\r\n\r\n\r\nrmse_avg\r\n\r\n\r\n2018\r\n\r\n\r\n1.1098768\r\n\r\n\r\n1.3661915\r\n\r\n\r\n2019\r\n\r\n\r\n0.6884056\r\n\r\n\r\n0.4085097\r\n\r\n\r\n2020\r\n\r\n\r\n1.0413089\r\n\r\n\r\n1.3118926\r\n\r\n\r\n2021\r\n\r\n\r\n1.8937623\r\n\r\n\r\n2.1905821\r\n\r\n\r\nYukarıdaki tablodan ve aşağıdaki grafikten görüleceği üzere RMSE\r\ndeğerlerini tek bir yıl hariç düşürdük ki sıfıra yaklaşması hiç tahmin\r\nhatası yapılmadığı anlamına geliyor.\r\n\r\n\r\n\r\nÇalışmada kümeleme algoritmasının simülasyonda faydalı olabileceğine\r\nodaklanmak istedim. Burada \\(\\mu\\) ve\r\n\\(\\sigma\\) değerlerinin, iş günü\r\nsayısının, küme sayısının en uygun şekilde seçimi önem kazanacaktır.\r\nGörsellere ait kodlara aşağıdan ulaşılabilir.\r\n\r\n\r\nggplot(df, aes(x = date, y = log(close), group = 1)) +\r\n  geom_line() +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        plot.title = element_text(face = \"bold\"),\r\n        plot.subtitle = element_text(face = \"italic\", size = 7),\r\n        plot.caption = element_text(face = \"italic\", size = 7)) +\r\n  labs(title = \"USDTRY Günlük Değerler\",\r\n       subtitle = \"01.01.2003 - 31.12.2021\",\r\n       caption = \"Değerler logaritmiktir.\\nVeriler Investing'ten alınmıştır.\")\r\n\r\nggplot(df, aes(x = date, y = logReturn, group = 1)) +\r\n  geom_line() +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        plot.title = element_text(face = \"bold\"),\r\n        plot.subtitle = element_text(face = \"italic\", size = 7),\r\n        plot.caption = element_text(face = \"italic\", size = 7)) +\r\n  labs(title = \"USDTRY Günlük Logaritmik Getiriler\",\r\n       subtitle = \"01.01.2003 - 31.12.2021\",\r\n       caption = \"Veriler Investing'ten alınmıştır.\")\r\n\r\nmusigma_hist %>% \r\n  select(-t) %>% \r\n  mutate(mu = scale(mu),\r\n         sigma = scale(sigma)) %>% \r\n  pivot_longer(!year, names_to = \"cons\", values_to = \"val\") %>% \r\n  ggplot(aes(x = factor(year), y = val, group = cons, color = cons)) +\r\n  geom_line() +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        plot.subtitle = element_text(face = \"italic\", size = 7),\r\n        plot.caption = element_text(face = \"italic\", size = 7),\r\n        legend.title = element_blank(),\r\n        legend.position = \"top\") +\r\n  labs(title = expression(\"Tarihsel \"~mu~\"ve\"~sigma~\"Değerleri\"),\r\n       subtitle = \"2003-2021\",\r\n       caption = \"Veriler standardize edilmiştir.\") +\r\n  scale_color_manual(values = c(\"red\",\"blue\"))\r\n\r\nggplot(gbmdf_master, aes(x = rn, group = sim)) +\r\n  geom_line(data = gbmdf_master %>% filter(!(sim %in% c(\"simAvg\",\"close\"))),\r\n            aes(y = value), color = \"gray80\") +\r\n  geom_line(data = gbmdf_master %>% filter(sim == \"simAvg\"),\r\n            aes(y = value), color = \"red\") +\r\n  geom_line(data = gbmdf_master %>% filter(sim == \"close\"),\r\n            aes(y = value), color = \"blue\") +\r\n  facet_wrap(~year, scales = \"free\") +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        plot.title = element_text(face = \"italic\", size = 7)) +\r\n  labs(title = \"Kırmızı: Ortalama Simüle, Mavi: Gerçek, Gri: Simüle\")\r\n\r\nggplot(joined_clusters_master, aes(x = rn, group = sim)) +\r\n  geom_line(data = joined_clusters_master %>% filter(!(sim %in% c(\"simAvg\",\"close\"))),\r\n            aes(y = value), color = \"gray80\") +\r\n  geom_line(data = joined_clusters_master %>% filter(sim == \"simAvg\"),\r\n            aes(y = value), color = \"red\") +\r\n  geom_line(data = joined_clusters_master %>% filter(sim == \"close\"),\r\n            aes(y = value), color = \"blue\") +\r\n  facet_wrap(~year, scales = \"free\") +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        plot.title = element_text(face = \"italic\", size = 7)) +\r\n  labs(title = \"Kırmızı: Ortalama Simüle, Mavi: Gerçek, Gri: Simüle\")\r\n\r\nrmse_df2 %>% \r\n  pivot_longer(!year, names_to = \"rmse_test_type\", values_to = \"RMSE\") %>% \r\n  ggplot(aes(x = year, y = RMSE, fill = rmse_test_type)) +\r\n  geom_bar(stat = \"identity\", position = position_dodge()) +\r\n  geom_text(aes(label = round(RMSE, digits = 4)),\r\n            position = position_dodge(width = 0.9), vjust = -0.2) +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        legend.title = element_blank(),\r\n        legend.position = \"top\") +\r\n  scale_fill_manual(values = c(\"gray30\",\"red\"))\r\n\r\n\r\n\r\nYararlandığım Kaynaklar:\r\nStokastik Süreçler ve R Uygulamaları; G.Ö.Kadılar\r\nBiyoenformatik DNA Mikrodizi Veri Madenciliği; Ç.S.Erol,\r\nY.Özkan\r\nRMSE:\r\nRoot Mean Square Error\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-05-22-post4/post4_files/figure-html5/unnamed-chunk-13-1.png",
    "last_modified": "2022-05-22T19:18:44+03:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-22-post5/",
    "title": "Twitter Verilerini Kullanarak Liderlerin Popülaritesini Ölçmek",
    "description": "Türkiye'deki bazı politik liderlerin Twitter'daki popülaritesi üzerine basit bir çalışma.",
    "author": [
      {
        "name": "A. Uraz Akgül",
        "url": {}
      }
    ],
    "date": "2022-05-22",
    "categories": [
      "Social Media"
    ],
    "contents": "\r\nTwitter geliştirici hesabı açmadan rtweet paketi ile belli\r\nsınırlarda veriler çekilebilir ve kısa vadeli analizler\r\ngerçekleştirilebilir. Bunun nasıl olabileceğini görelim.\r\nUygulamada, isim ve gündem olarak ön plana çıkmış bazı politik\r\nliderlerin tweetlerini çekip zamanla popülaritelerinde nasıl bir değişim\r\nolmuş bunu inceleyeceğiz.\r\nPopülariteyi ölçmek için birtakım indikatörleri bir araya getirmemiz\r\ngerekir ancak bu uygulamada tek bir indikatör olarak tweetlerine gelen\r\nbeğeni sayılarını alacağız.\r\n\r\n\r\n#install.packages(\"rtweet\")\r\nlibrary(rtweet)\r\nlibrary(tidyverse)\r\n\r\n\r\n\r\nBaşlamadan önce bir not: rtweet paketinin fonksiyonlarını kullanmaya\r\nbaşladığınız zaman karşınıza bir authentication (kimlik doğrulama)\r\nsayfası gelecektir. Bu noktada giriş yapmanız yeterli olacaktır. Giriş\r\nyaptıktan sonra authentication gerçekleşmiş olacaktır.\r\nAşağıdaki liderlerin tweetlerini çekerek başlayalım.\r\n\r\n\r\nleaders <- c(\r\n  \"RTErdogan\",\r\n  \"kilicdarogluk\",\r\n  \"meral_aksener\",\r\n  \"ekrem_imamoglu\",\r\n  \"mansuryavas06\",\r\n  \"umitozdag\",\r\n  \"alibabacan\",\r\n  \"Ahmet_Davutoglu\"\r\n)\r\n\r\n\r\n\r\nrtweet paketindeki get_timeline() fonksiyonu ile bir hesabın\r\ntweetlerini diğer tüm detayları ile birlikte çekebiliriz.\r\nDokümantasyonda yer alan bilgiye göre maksimum 3200 tweet\r\nçekebiliyoruz.\r\nhttps://www.rdocumentation.org/packages/rtweet/versions/0.7.0/topics/get_timeline\r\n\r\nmaster <- data.frame()\r\n\r\nfor(i in 1:length(leaders)){\r\n  \r\n  user_tl <- get_timeline(\r\n    user = leaders[i],\r\n    n = Inf, # alınabilecek maksimum tweet sayısıdır; girilmezse default 100 tane çeker\r\n  )\r\n  \r\n  # her bir hesabın çekilen tweetlerini (user_tl) master veri çerçevesinde birleştir\r\n  master <- master %>% \r\n    bind_rows(user_tl)\r\n  \r\n  Sys.sleep(time = 1) # döngü her çalıştığında 1 saniye bekletebiliriz\r\n  # sık gönderilen isteklerde problem olmaması için kullanılabilecek bir fonksiyon\r\n  \r\n}\r\n\r\n\r\n\r\nVeri çerçevesini biraz düzenleyelim.\r\n\r\n\r\ndf <- master %>% \r\n  filter(!is_retweet) %>% # retweetler kaldırıldı\r\n  select(created_at,name,favorite_count) %>% # 3 adet kolon seçildi\r\n  mutate(created_at = as.Date(created_at)) # tarih formatı düzeltildi (sadece yyyy-mm-dd)\r\n\r\n\r\n\r\nHer bir liderin 2022 yılında attığı toplam tweet ve beğeni sayısına\r\nbakalım.\r\n\r\n\r\ndf2022 <- df %>% \r\n  filter(created_at >= as.Date(\"2022-01-01\")) %>% \r\n  group_by(name) %>% \r\n  summarise(\r\n    n = n(), # toplam tweet sayısı\r\n    totalFav = sum(favorite_count) # toplam beğeni sayısı\r\n  )\r\n\r\n\r\n\r\n\r\n\r\n\r\nBir de 2022 yılına ait tweet başına düşen beğeni sayısına\r\nbakalım.\r\n\r\n\r\ndf2022 <- df2022 %>% \r\n  mutate(lpt = totalFav / n) # lpt: like per tweet (tweet başına beğeni)\r\n\r\n\r\n\r\n\r\n\r\nggplot(df2022, aes(x = reorder(name,lpt), y = lpt, fill = lpt)) +\r\n  geom_col() +\r\n  coord_flip() +\r\n  theme_minimal() +\r\n  theme(legend.position = \"none\") +\r\n  scale_y_continuous(labels = scales::comma) +\r\n  scale_fill_gradient(low = \"orange\", high = \"red\") +\r\n  labs(x = \"\", y = \"Tweet Başına Beğeni Sayısı\")\r\n\r\n\r\n\r\n\r\n2022 yılına ait günlük bazda popülaritenin zaman ile olan eğilimine\r\nbakabiliriz.\r\n\r\n\r\ndf_pop <- df %>% \r\n  filter(created_at >= as.Date(\"2022-01-01\")) %>% \r\n  group_by(name,created_at) %>% \r\n  summarise(\r\n    n = n(),\r\n    totalFav = sum(favorite_count)\r\n  ) %>% \r\n  mutate(lpt = totalFav / n) %>% \r\n  group_by(name) %>% \r\n  mutate(t = row_number()) # t: gözlem sayısı\r\n\r\n\r\n\r\n\r\n\r\nggplot(df_pop, aes(x = t, y = lpt)) +\r\n  geom_line(color = \"gray\") +\r\n  geom_point(color = \"gray40\") +\r\n  geom_smooth(method = \"loess\", color = \"red\") +\r\n  facet_wrap(~name, scales = \"free\") +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        axis.text.y = element_text(size = 7),\r\n        axis.text.x = element_blank(),\r\n        plot.title = element_text(face = \"bold\"),\r\n        plot.subtitle = element_text(face = \"italic\")) +\r\n  scale_y_continuous(labels = scales::unit_format(unit = \"K\", scale = 1e-3, sep = \"\")) +\r\n  labs(title = \"Günlük Tweet Başına Beğeni Sayısı, 2022\",\r\n       subtitle = \"Günlük Toplam Beğeni / Günlük Toplam Tweet\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-05-22-post5/post5_files/figure-html5/unnamed-chunk-10-1.png",
    "last_modified": "2022-05-22T19:46:05+03:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-19-post3/",
    "title": "Faizdeki Değişimin Enflasyon Üzerindeki Etkisinin Markov Zinciri Modeli ile Analizi",
    "description": "Enflasyonun uzun dönemde yükselmesi olasılığı 70%'tir.",
    "author": [
      {
        "name": "A. Uraz Akgül",
        "url": {}
      }
    ],
    "date": "2022-05-19",
    "categories": [
      "Finance",
      "Economics"
    ],
    "contents": "\r\nMarkov süreci, bir stokastik sürecin şu anki değerleri bilindiğinde,\r\nsürecin gelecekteki değerlerinin geçmişteki değerlerinden koşullu olarak\r\nbağımsız olduğu süreçtir. Markov zinciri ise Markov sürecinin kesikli\r\ndurum uzayına sahip olduğu özel bir durumdur. Stokastik sistemlerin kısa\r\nveya uzun dönemdeki davranışlarının modellenmesinde Markov\r\nzincirlerinden yararlanılmaktadır.\r\nAylık frekansta olan ve Haziran 2018 (başkanlık sistemi) ile Nisan\r\n2022 (son veri) arasını kapsayan verileri TCMB/EVDS’den aldım. Faizi\r\ntemsilen Ağırlık Ortalama Fonlama Maliyeti’ni; enflasyonu temsilen de\r\nTÜFE’den elde edilen yıllık değişimleri kullandım. Verilere\r\n(post3.xlsx) GitHub\r\nhesabımdan ulaşabilirsiniz.\r\n\r\n\r\nlibrary(kableExtra) # zorunlu değil\r\nlibrary(expm) # %^% operatörü\r\nlibrary(markovchain) # uzun dönem denge hesaplaması\r\nlibrary(tidyverse)\r\nlibrary(ggalluvial)\r\n\r\ndf <- readxl::read_excel(\"data.xlsx\")\r\ndf <- df %>% \r\n  mutate(tarih = as.Date(paste0(tarih,\"-\",1))) %>% \r\n  filter(tarih >= as.Date(\"2018-06-01\")) %>% \r\n  na.omit() # Mayıs 2022 verisi çıkarıldı.\r\n\r\n\r\n\r\n\r\n\r\n\r\nElimizdeki durumların (State; S1, S2, …) neler olabileceğine\r\nbakalım:\r\nS1: Faiz Yükseldi - Enflasyon Yükseldi\r\nS2: Faiz Yükseldi - Enflasyon Düştü\r\nS3: Faiz Düştü - Enflasyon Yükseldi\r\nS4: Faiz Düştü - Enflasyon Düştü\r\nS5: Faiz Değişmedi - Enflasyon Yükseldi\r\nS6: Faiz Değişmedi - Enflasyon Düştü\r\n\r\n\r\ndf2 <- df %>% \r\n  mutate(\r\n    durum = case_when(\r\n      lead(faiz) > faiz & lead(enflasyon) > enflasyon ~ \"S1\",\r\n      lead(faiz) > faiz & lead(enflasyon) < enflasyon ~ \"S2\",\r\n      lead(faiz) < faiz & lead(enflasyon) > enflasyon ~ \"S3\",\r\n      lead(faiz) < faiz & lead(enflasyon) < enflasyon ~ \"S4\",\r\n      lead(faiz) == faiz & lead(enflasyon) > enflasyon ~ \"S5\",\r\n      lead(faiz) == faiz & lead(enflasyon) < enflasyon ~ \"S6\",\r\n    ) # lead() ---> bir sonraki durum; t + 1 ile t karşılaştırılıyor\r\n  ) %>% \r\n  na.omit() %>% # NA içeren değerler çıkarıldı\r\n  select(durum) # yeterli olacak sütun\r\n\r\n\r\n\r\nKesikli parametreli Markov zincirlerinde sistem belirli bir olasılık\r\ndağılımına bağlı olarak bulunduğu durumdan başka bir duruma geçebilir\r\nveya aynı durumda kalabilir. Bu nedenle, incelenen sistemin içinde\r\nbulunabileceği farklı durumların ve bu durumların birinden diğerine\r\ngeçiş olasılıklarını bilmemiz gerekir. Sistemin bu durum değişiklikleri\r\ngeçiş olarak isimlendirilir ve durum uzayındaki herhangi i ve j\r\ndurumları için, \\(p_{ij}(m,n) = P(X_{m+n} =\r\nj/X_m = i)\\) biçimindeki koşullu olasılığa geçiş olasılığı adı\r\nverilir. Ayrıca, homojen bir Markov zincirinde geçiş olasılığı yalnızca\r\nadım sayısının bir fonksiyonudur ve m zamanına bağlı değildir.\r\nYukarıdaki durumları baz alarak Markov geçiş matrisini\r\noluşturalım.\r\n\r\n\r\nmgm <- df2 %>% \r\n  mutate(\r\n    durum2 = lead(durum)\r\n  ) %>% # hangi durumdan hangi duruma geçti\r\n  na.omit() %>% \r\n  group_by(durum,durum2) %>% \r\n  summarise(n = n()) %>% \r\n  ungroup()\r\n\r\n\r\n\r\nTabloda olmayan bazı durumlar var. Bunları tüm durumları baz alarak\r\nekleyebiliriz.\r\n\r\n\r\ntumDurumlar <- data.frame(\r\n  durum = paste0(\"S\",seq(1,6,1)), # tüm durumlar\r\n  durum2 = paste0(\"S\",seq(1,6,1)) # tüm durumlar 2\r\n) %>% \r\n  expand(durum,durum2) %>% # tüm durumlar burada genişletiliyor\r\n  left_join(mgm, by = c(\"durum\",\"durum2\")) %>% \r\n  mutate(n = replace(n,is.na(n),0))\r\n\r\n\r\n\r\n\r\n\r\n\r\nMatrisi oluşturabiliriz. Her bir hücreyi o satırın toplamına bölerek\r\nolasılıkları hesaplayacağız.\r\n\r\n\r\nm <- tumDurumlar %>% \r\n  pivot_wider(names_from = \"durum2\", values_from = \"n\") %>% # sütun\r\n  column_to_rownames(var = \"durum\") %>% # satır\r\n  mutate_all(.funs = function(x) round(x / rowSums(.), digits = 2)) %>% \r\n  mutate_if(is.numeric, funs(ifelse(is.nan(.), 0, .))) %>% \r\n  as.matrix()\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nS1\r\n\r\n\r\nS2\r\n\r\n\r\nS3\r\n\r\n\r\nS4\r\n\r\n\r\nS5\r\n\r\n\r\nS6\r\n\r\n\r\nS1\r\n\r\n\r\n0.38\r\n\r\n\r\n0.12\r\n\r\n\r\n0.25\r\n\r\n\r\n0.12\r\n\r\n\r\n0.12\r\n\r\n\r\n0.00\r\n\r\n\r\nS2\r\n\r\n\r\n0.50\r\n\r\n\r\n0.00\r\n\r\n\r\n0.25\r\n\r\n\r\n0.25\r\n\r\n\r\n0.00\r\n\r\n\r\n0.00\r\n\r\n\r\nS3\r\n\r\n\r\n0.07\r\n\r\n\r\n0.07\r\n\r\n\r\n0.47\r\n\r\n\r\n0.13\r\n\r\n\r\n0.13\r\n\r\n\r\n0.13\r\n\r\n\r\nS4\r\n\r\n\r\n0.00\r\n\r\n\r\n0.14\r\n\r\n\r\n0.43\r\n\r\n\r\n0.43\r\n\r\n\r\n0.00\r\n\r\n\r\n0.00\r\n\r\n\r\nS5\r\n\r\n\r\n0.12\r\n\r\n\r\n0.00\r\n\r\n\r\n0.12\r\n\r\n\r\n0.00\r\n\r\n\r\n0.62\r\n\r\n\r\n0.12\r\n\r\n\r\nS6\r\n\r\n\r\n0.33\r\n\r\n\r\n0.33\r\n\r\n\r\n0.00\r\n\r\n\r\n0.00\r\n\r\n\r\n0.33\r\n\r\n\r\n0.00\r\n\r\n\r\nYukarıdaki matris bir-adım geçiş olasılığı matrisidir. Homojen bir\r\nMarkov zincirinde m. adımda i durumunda bulunan sürecin bir adım sonra j\r\ndurumunda bulunması olasılığı \\(p_{ij} =\r\np_{ij}(1) = p_{ij}^{(1)} = P(X_{m+1} = j/X_m = i)\\)’dir.\r\nYukarıdaki bir-adım geçiş matrisinde satırlar sistemin şu an\r\nbulunabileceği durumları; sütunlar ise bir adım sonra bulunabileceği\r\ndurumları göstermektedir.\r\nBaşlangıç durumu S5’tir. Yani, faiz değişmedi - enflasyon yükseldi.\r\nGelecek Mayıs ayına ait olasılıklara bakalım.\r\n\r\n\r\nbaslangicDurum <- matrix(\r\n  data = c(0,0,0,0,1,0), # S5 ---> 1; diğerleri 0\r\n  nrow = 1,\r\n  byrow = TRUE\r\n)\r\n\r\n\r\n\r\n\r\n\r\nbaslangicDurum %*% m\r\n\r\n\r\n\r\n\r\n\r\nS1\r\n\r\n\r\nS2\r\n\r\n\r\nS3\r\n\r\n\r\nS4\r\n\r\n\r\nS5\r\n\r\n\r\nS6\r\n\r\n\r\n0.12\r\n\r\n\r\n0\r\n\r\n\r\n0.12\r\n\r\n\r\n0\r\n\r\n\r\n0.62\r\n\r\n\r\n0.12\r\n\r\n\r\nFaizin değişmediği ve enflasyonun yükseldiği bir dönemden yine faizin\r\ndeğişmediği ve enflasyonun yükseldiği bir döneme geçiş olasılığı\r\n62%’dir.\r\nPeki, Haziran ayı için (iki-adım geçiş) olasılıklar ne olacaktır?\r\n\r\n\r\nm %^% 2 %>% as.matrix() %>% round(., digits = 2)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nS1\r\n\r\n\r\nS2\r\n\r\n\r\nS3\r\n\r\n\r\nS4\r\n\r\n\r\nS5\r\n\r\n\r\nS6\r\n\r\n\r\nS1\r\n\r\n\r\n0.24\r\n\r\n\r\n0.08\r\n\r\n\r\n0.31\r\n\r\n\r\n0.16\r\n\r\n\r\n0.15\r\n\r\n\r\n0.05\r\n\r\n\r\nS2\r\n\r\n\r\n0.21\r\n\r\n\r\n0.11\r\n\r\n\r\n0.35\r\n\r\n\r\n0.20\r\n\r\n\r\n0.09\r\n\r\n\r\n0.03\r\n\r\n\r\nS3\r\n\r\n\r\n0.15\r\n\r\n\r\n0.10\r\n\r\n\r\n0.33\r\n\r\n\r\n0.14\r\n\r\n\r\n0.19\r\n\r\n\r\n0.08\r\n\r\n\r\nS4\r\n\r\n\r\n0.10\r\n\r\n\r\n0.09\r\n\r\n\r\n0.42\r\n\r\n\r\n0.28\r\n\r\n\r\n0.06\r\n\r\n\r\n0.06\r\n\r\n\r\nS5\r\n\r\n\r\n0.17\r\n\r\n\r\n0.06\r\n\r\n\r\n0.16\r\n\r\n\r\n0.03\r\n\r\n\r\n0.45\r\n\r\n\r\n0.09\r\n\r\n\r\nS6\r\n\r\n\r\n0.33\r\n\r\n\r\n0.04\r\n\r\n\r\n0.20\r\n\r\n\r\n0.12\r\n\r\n\r\n0.24\r\n\r\n\r\n0.04\r\n\r\n\r\nMarkov zincirinde ilk olasılık dağılımı ve zincirin bir-adım geçiş\r\nmatrisini belirlediğimizde zincirin tüm adımlarındaki olasılıkları\r\nkolayca elde edebiliriz. n-adım olasılıklı vektörü \\(\\pi_{n} = \\pi_{n-1}P\\) olsun. Buradan\r\naşağıdaki eşitlikleri türetebiliriz.\r\n\\(\\pi_n = (\\pi_{n-2}P)P =\r\n\\pi_{n-2}P^2\\)\r\n.\r\n.\r\n.\r\n\\(\\pi_n = \\pi_0P^n\\)\r\nP geçiş matrisinin n. kuvvetini aldığımızda elde edeceğimiz n-adım\r\ngeçiş matrisi \\(P^n\\)’de n değeri\r\nbüyüdükçe \\(P_{ij}^{(n)}\\) olasılık\r\ndeğerleri sabit bir değere ya da limite yaklaşıyorsa, n-adım geçiş\r\nolasılıkları denge durumuna ulaşır. Denge durumuna ulaştığımızda geçiş\r\nmatrisinin satırlarında değişim olmadığını göreceğiz. Yani, her satırı\r\naynı olan bir geçiş matrisi elde edeceğiz.\r\n\\(\\pi_n = [\\pi_0 \\pi_1 ...\r\n\\pi_n]\\)\r\n\r\n\r\nm <- tumDurumlar %>% \r\n  pivot_wider(names_from = \"durum2\", values_from = \"n\") %>% # sütun\r\n  column_to_rownames(var = \"durum\") %>% # satır\r\n  mutate_all(.funs = function(x) x / rowSums(.)) %>% \r\n  # satır toplamı 1 olması için round() kaldırıldı\r\n  mutate_if(is.numeric, funs(ifelse(is.nan(.), 0, .))) %>% \r\n  as.matrix()\r\n\r\nn_adim <- new(\r\n  \"markovchain\",\r\n  transitionMatrix = matrix(as.numeric(m), nrow = 6, ncol = 6)\r\n)\r\n\r\n\r\n\r\n\r\n\r\nsteadyStates(n_adim) %>% round(. ,digits = 2)\r\n\r\n\r\n\r\n\r\n\r\n1\r\n\r\n\r\n2\r\n\r\n\r\n3\r\n\r\n\r\n4\r\n\r\n\r\n5\r\n\r\n\r\n6\r\n\r\n\r\n0.18\r\n\r\n\r\n0.09\r\n\r\n\r\n0.29\r\n\r\n\r\n0.15\r\n\r\n\r\n0.23\r\n\r\n\r\n0.07\r\n\r\n\r\nUzun dönemde;\r\nFaizin yükseldiği ve enflasyonun yükseldiği dönem olasılığı\r\n18%,\r\nFaizin yükseldiği ve enflasyonun düştüğü dönem olasılığı\r\n9%,\r\nFaizin düştüğü ve enflasyonun yükseldiği dönem olasılığı\r\n29%,\r\nFaizin düştüğü ve enflasyonun düştüğü dönem olasılığı\r\n15%,\r\nFaizin değişmediği ve enflasyonun yükseldiği dönem olasılığı\r\n23%,\r\nFaizin değişmediği ve enflasyonun düştüğü dönem olasılığı\r\n7%’dir.\r\nDeğerlerin toplamı yuvarlamadan dolayı 100% değildir.\r\nYukarıdaki olasılıkları baz aldığımızda uzun vadede enflasyonun\r\nyükselmesi olasılığı 70% iken; düşmesi olasılığı 30%’dur.\r\nGörsellere ait kodlara aşağıdan ulaşılabilir.\r\n\r\n\r\ndf %>% \r\n  rename(\"AOFM\"=2, \"Enflasyon\"=3) %>% \r\n  pivot_longer(!tarih, names_to = \"variables\", values_to = \"values\") %>% \r\n  ggplot(aes(x = tarih, y = log(values), group = variables, color = variables)) +\r\n  geom_line() +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        legend.title = element_blank(),\r\n        legend.position = \"top\",\r\n        plot.title = element_text(face = \"bold\"),\r\n        plot.subtitle = element_text(face = \"italic\", size = 7),\r\n        plot.caption = element_text(face = \"italic\", size = 5)) +\r\n  scale_color_manual(values = c(\"blue\",\"red\")) +\r\n  labs(title = \"Ağırlıklı Ortalama Fonlama Faizi ve Enflasyon (YoY)\",\r\n       subtitle = \"Ocak 2011 - Nisan 2022\",\r\n       caption = \"Değerler logaritmiktir.\\nVeriler TCMB/EVDS'den alınmıştır.\")\r\n\r\nggplot(data = tumDurumlar, aes(axis1 = durum, axis2 = durum2, y = n)) +\r\n  geom_alluvium(aes(fill = durum2)) +\r\n  geom_stratum(fill = \"gray15\") +\r\n  geom_text(stat = \"stratum\", aes(label = after_stat(stratum)), color = \"white\") +\r\n  scale_x_discrete(limits = c(\"durum\", \"durum2\"), expand = c(0.15, 0.05)) +\r\n  theme_void() + \r\n  theme(legend.position = \"none\") +\r\n  scale_fill_viridis_d()\r\n\r\n\r\n\r\nYararlandığım Kaynaklar:\r\nStokastik Süreçler ve R Uygulamaları; G.Ö.Kadılar\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-05-19-post3/post3_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2022-05-29T01:32:01+03:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-04-post2/",
    "title": "Merkez Bankası Rezervleri Nasıl Hesaplanır?",
    "description": "Bir fonksiyon ile güncel rezerv değerine kolay erişim.",
    "author": [
      {
        "name": "A. Uraz Akgül",
        "url": {}
      }
    ],
    "date": "2022-05-04",
    "categories": [
      "Finance"
    ],
    "contents": "\r\nRezervlerin R’da nasıl hesaplanabileceğini göstermek için Mahfi\r\nEğilmez’in Rezerv\r\nMeselesi başlıklı bulabildiğim en güncel yazısından faydalandım. En\r\ngüncel diyorum çünkü diğer yazılarına göre farklılıklar gördüm ve en\r\ngüncelin en doğru olabileceğini düşündüm. Tabi ki hesaplama ile ilgili\r\ngörüş farklılıkları çıkacaktır ancak bu tartışma bu yazının konusu\r\ndeğildir.\r\nÜç ana konuyu öğretmeyi hedefliyorum: 1) TCMB’den veri nasıl çekilir?\r\n2) R’da bu hesaplamayı nasıl otomatik hale getirebiliriz? 3)\r\nRezervlerimiz nasıl hesaplanıyor?\r\nTCMB EVDS sistemine üye nasıl olunur ve sistemden API\r\nanahtarı nasıl alınır?\r\nTCMB’nin Elektronik Veri Dağıtım Sistemi olan EVDS’ye buradan ulaşabilirsiniz.\r\nDokümantasyon okumayı alışkanlık haline getirmeliyiz. Bunun için sayfada\r\nyer alan Kullanıcı\r\nDokümanları başlığına tıklayıp Web\r\nServis Kullanım Kılavuzu’na erişiyoruz.\r\nTCMB bu doküman ile web servis metotlarının parametrelerini\r\naçıklamış. Bu sayfa şimdilik kalsın.\r\nYine aynı sayfada yer alan Giriş Yap\r\nbölümüne giriyoruz. Daha önce kayıt olmadıysanız Kayıt Olun\r\nseçeneği ile kayıt işleminizi yapabilirsiniz. Ardından kullanıcı\r\nadı, parola ve doğrulama kodu ile giriş\r\nyapılabilir. Bundan sonra bir API anahtarına ihtiyacınız olacak. Bunun\r\niçin de isminiz ve soyisminizin yer aldığı yerden profilinize gidip\r\nAPI Anahtarı butonuna tıklayabilirsiniz. Tarayıcınızda çıkan\r\nbir mesaj ile API anahtarınız verilecek. Bunu kopyalayın ya da aşağıdaki\r\ngibi bir objeye kaydedin.\r\n\r\n\r\napi_key <- \"api_anahtariniz\"\r\n\r\n\r\n\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(jsonlite)\r\n\r\n\r\n\r\nBaşlamadan bir not: Önce detaylı bir şekilde açıklayacağım,\r\nsonrasında öğrendiklerimizi tek bir fonksiyonda toplayıp vereceğim.\r\nBaşlamadan diğer bir not: Önce yazıda hesaplanan değerlere ulaşıp bir\r\nnevi değerleri teyit edeceğiz; ardından güncel rezervi\r\nhesaplayacağız.\r\nRezervleri Hesaplamak İçin Denklemler:\r\nNet Rezervler = (Dış Varlıklar / O günkü TCMB USD Alış Kuru) - (Döviz\r\nYükümlülükleri / O günkü TCMB USD Alış Kuru)\r\nSwaplar = Döviz Swapları + Altın Swapları\r\nSwap Hariç Net Rezervler = Net Rezervler - Swaplar\r\nNet Rezervler\r\nNet Rezervler = (Dış Varlıklar / O günkü TCMB USD Alış Kuru) - (Döviz\r\nYükümlülükleri / O günkü TCMB USD Alış Kuru)\r\nEVDS’deki yeri: Tüm Seriler > TCMB Bilanço Verileri > Merkez\r\nBankası Analitik Bilanço (Bin TL)\r\nWeb Servis ile almak için aşağıdaki adımları takip edebiliriz.\r\nKategorileri görelim.\r\nDokümanda 4 no’lu EVDS Metaveri web servisleri başlığı\r\naltındaki 4.1 no’lu Konu Başlığı Servisi alt başlığında\r\nbulunmaktadır.\r\nTüm konu başlıklarını sunan bir servistir. Bu servisi temsilen\r\n“https://evds2.tcmb.gov.tr/service/evds/” tanımından\r\nsonra “categories” eklenmelidir.\r\nhttps://evds2.tcmb.gov.tr/service/evds/categories/key=XXXXXX&type=xml\r\nUzantısı xml olsa da biz bunu json ile alabiliriz (json için jsonlite\r\npaketinin fromJSON() fonksiyonundan faydalanacağız).\r\n\r\n\r\nurl_kategori <- paste0(\"https://evds2.tcmb.gov.tr/service/evds/categories/key=\",\r\n                       api_key,\r\n                       \"&type=json\")\r\n\r\ndf_kategori <- fromJSON(url_kategori) %>%\r\n  as.data.frame() %>%\r\n  select(CATEGORY_ID,TOPIC_TITLE_TR)\r\n\r\nkategori_id <- df_kategori %>% \r\n  filter(TOPIC_TITLE_TR == 'TCMB BİLANÇO VERİLERİ') %>% \r\n  pull(CATEGORY_ID)\r\n\r\n\r\n\r\n2 sütun ve 24 satırdan oluşan df_kategori objesini aldık. TCMB\r\nBilanço Verileri’nin kategori ID’si 13’tür.\r\nVeri gruplarını görelim.\r\nDokümanda 4 no’lu EVDS Metaveri web servisleri başlığı\r\naltındaki 4.2 no’lu Veri Grubu Servisi alt başlığında\r\nbulunmaktadır.\r\nİlgili Konu başlığı bazında ya da tek bir veri grubunun metaveri\r\nbilgilerini listeleyen bir servistir. Bu servisi temsilen “https://evds2.tcmb.gov.tr/service/evds/” tanımından\r\nsonra “datagroups” eklenmelidir.\r\nhttps://evds2.tcmb.gov.tr/service/evds/datagroups/key=XXXX&mode=1&code=bie_yssk&type=json\r\nhttps://evds2.tcmb.gov.tr/service/evds/datagroups/key=XXXX&mode=2&code=2&type=xml\r\nVerilen örneklerde mode=1 ve mode=2 olarak verilse de biz mode=0\r\nolarak kullanacağız. Çünkü tüm konu başlıkları altındaki tüm veri\r\ngruplarını göreceğiz.\r\n\r\n\r\nurl_verigrubu <- paste0(\"https://evds2.tcmb.gov.tr/service/evds/datagroups/key=\",\r\n                        api_key,\r\n                        \"&mode=0&type=json\")\r\n\r\ndf_verigrubu <- fromJSON(url_verigrubu) %>% \r\n  as.data.frame() %>% \r\n  filter(CATEGORY_ID == kategori_id) %>% \r\n  select(CATEGORY_ID,\r\n         DATAGROUP_CODE,\r\n         DATAGROUP_NAME,\r\n         FREQUENCY_STR,\r\n         NOTE,\r\n         START_DATE,\r\n         END_DATE)\r\n\r\nverigrubu_kodu <- df_verigrubu %>% \r\n  filter(DATAGROUP_NAME == 'Merkez Bankası Analitik Bilanço(Bin TL)') %>% \r\n  pull(DATAGROUP_CODE)\r\n\r\n\r\n\r\n7 sütun ve 6 satırdan oluşan df_verigrubu objesini aldık. Merkez\r\nBankası Analitik Bilanço(Bin TL)’nin veri grubu kodu\r\nbie_abanlbil’dir.\r\nSerileri görelim.\r\nDokümanda 4 no’lu EVDS Metaveri web servisleri başlığı\r\naltındaki 4.3 no’lu Seri Listesi Servisi alt başlığında\r\nbulunmaktadır.\r\nSeri listesini veri grubu ya da seri kodu bazında sunan bir\r\nservistir. Bu servisi temsilen “https://evds2.tcmb.gov.tr/service/evds/” tanımından\r\nsonra “serieList” eklenmelidir.\r\nhttps://evds2.tcmb.gov.tr/service/evds/serieList/key=XXXXX&type=xml&code=TP.DK.USD.A\r\nhttps://evds2.tcmb.gov.tr/service/evds/serieList/key=XXXXX&type=csv&code=bie_yssk\r\nBiz kodumuzu bildiğimiz için örnekte verilen code= kısmına kendi\r\nkodumuzu yazacağız.\r\n\r\n\r\nurl_seri <- paste0(\"https://evds2.tcmb.gov.tr/service/evds/serieList/key=\",\r\n                   api_key,\r\n                   \"&type=json&code=\",\r\n                   verigrubu_kodu)\r\n\r\ndf_seri <- fromJSON(url_seri) %>% \r\n  as.data.frame() %>% \r\n  select(SERIE_CODE,\r\n         DATAGROUP_CODE,\r\n         SERIE_NAME,\r\n         FREQUENCY_STR,\r\n         DEFAULT_AGG_METHOD_STR,\r\n         DEFAULT_AGG_METHOD,\r\n         START_DATE,\r\n         END_DATE)\r\n\r\nseri <- df_seri %>% \r\n  filter(SERIE_NAME %in% c('A.1-DIŞ VARLIKLAR(Bin TL)',\r\n                           'P.1-TOPLAM DÖVİZ YÜKÜMLÜLÜKLERİ(Bin TL)')) %>% \r\n  pull(SERIE_CODE)\r\n\r\n\r\n\r\n8 sütun ve 31 satırdan oluşan df_seri objesini aldık. A.1-DIŞ\r\nVARLIKLAR(Bin TL)’nin seri kodu TP.AB.A02; P.1-TOPLAM DÖVİZ\r\nYÜKÜMLÜLÜKLERİ(Bin TL)’nin seri kodu TP.AB.A10’dur.\r\nSon olarak verileri alabiliriz. URL olarak temelde https://evds2.tcmb.gov.tr/service/evds/series=\r\nkullanacağız. Sonrası ise parametrelerin eklenmesi olacak. Dokümanda\r\nbununla ilgili açıklayıcı örnekler bulunmaktadır.\r\nAşağıdaki örnekte url’den sonra seri kodlarının arasına “-” koyduk.\r\nYani, birden fazla seriyi alabiliyoruz. Devamında ise başlangıç ve bitiş\r\ntarihlerine sırasıyla &startDate= ve &endDate= ile adres\r\ngösterdik. Bunlara ek olarak url’e frekans tipini ekleyeceğiz çünkü bu\r\nseri default iş günü olarak geliyor ve bunu haftalık yapmamız gerekir.\r\nEklenecek olan parametre frequency ve haftalık olduğu için 3\r\ndiyeceğiz.\r\n\r\n\r\nhaftalikTarih <- \"26-02-2021\"\r\nfrekans <- 3\r\n\r\nurl_veri <- paste0(\"https://evds2.tcmb.gov.tr/service/evds/series=\",\r\n                   seri[1],\r\n                   \"-\",\r\n                   seri[2],\r\n                   \"&startDate=\",\r\n                   haftalikTarih,\r\n                   \"&endDate=\",\r\n                   haftalikTarih,\r\n                   \"frequency=\",\r\n                   frekans,\r\n                   \"&type=json&key=\",\r\n                   api_key)\r\n\r\ndf_veri <- fromJSON(url_veri) %>% \r\n  as.data.frame() %>% \r\n  select(2,3,4) %>% \r\n  rename(\r\n    \"Tarih\"=1,\r\n    \"A.1-DIŞ VARLIKLAR(Bin TL)\"=2,\r\n    \"P.1-TOPLAM DÖVİZ YÜKÜMLÜLÜKLERİ(Bin TL)\"=3\r\n  )\r\n\r\n\r\n\r\nDış varlıklardan toplam döviz yükümlülüklerini çıkaracağız ancak\r\nçıkacak olan fark TL cinsinden olduğu için bunu dolara çevirmemiz\r\ngerekiyor. Bunu da o güne ait kur üzerinden yapacağız (yazıda hesaplama\r\nyapılırken 15:30’da belirlenen gösterge niteliğindeki Merkez Bankası\r\nkuru kullanılıyor; biz ise EVDS sisteminden aldığımız kuru\r\nkullanacağız).\r\n26 Şubat 2021’deki USD/TL kur değerine ulaşalım. Kurlar’ın bulunduğu\r\nkategorinin ID’si 2’dir. Bunun yanında Kurlar-Döviz Kurları’nın veri\r\ngrubu kodu bie_dkdovytl; (USD) ABD Doları (Döviz Alış)’ın seri kodu\r\nTP.DK.USD.A.YTL’dir.\r\n\r\n\r\nkategori_id_2 <- df_kategori %>% \r\n  filter(TOPIC_TITLE_TR == 'KURLAR') %>% \r\n  pull(CATEGORY_ID)\r\n\r\ndf_verigrubu_2 <- fromJSON(url_verigrubu) %>% \r\n  as.data.frame() %>% \r\n  filter(CATEGORY_ID == kategori_id_2) %>% \r\n  select(CATEGORY_ID,\r\n         DATAGROUP_CODE,\r\n         DATAGROUP_NAME,\r\n         FREQUENCY_STR,\r\n         NOTE,\r\n         START_DATE,\r\n         END_DATE)\r\n\r\nverigrubu_kodu_2 <- df_verigrubu_2 %>% \r\n  filter(DATAGROUP_NAME == 'Kurlar-Döviz Kurları') %>% \r\n  pull(DATAGROUP_CODE)\r\n\r\nurl_seri_2 <- paste0(\"https://evds2.tcmb.gov.tr/service/evds/serieList/key=\",\r\n                     api_key,\r\n                     \"&type=json&code=\",\r\n                     verigrubu_kodu_2)\r\n\r\ndf_seri_2 <- fromJSON(url_seri_2) %>% \r\n  as.data.frame() %>% \r\n  select(SERIE_CODE,\r\n         DATAGROUP_CODE,\r\n         SERIE_NAME,\r\n         FREQUENCY_STR,\r\n         DEFAULT_AGG_METHOD_STR,\r\n         DEFAULT_AGG_METHOD,\r\n         START_DATE,\r\n         END_DATE)\r\n\r\nseri_2 <- df_seri_2 %>% \r\n  filter(SERIE_NAME == '(USD) ABD Doları (Döviz Alış)') %>% \r\n  pull(SERIE_CODE)\r\n\r\nurl_veri_2 <- paste0(\"https://evds2.tcmb.gov.tr/service/evds/series=\",\r\n                     seri_2,\r\n                     \"&startDate=\",\r\n                     haftalikTarih,\r\n                     \"&endDate=\",\r\n                     haftalikTarih,\r\n                     \"&type=json&key=\",\r\n                     api_key)\r\n\r\ndf_veri_2 <- fromJSON(url_veri_2) %>% \r\n  as.data.frame() %>% \r\n  select(2,3) %>% \r\n  rename(\r\n    \"Tarih\"=1,\r\n    \"(USD) ABD Doları (Döviz Alış)\"=2\r\n  )\r\n\r\n\r\n\r\nNet Rezerv aşağıdaki gibi hesaplanabilir.\r\n\r\n\r\n# Birimler Bin TL'dir.\r\n\r\ndis_varliklar <- as.numeric(df_veri$`A.1-DIŞ VARLIKLAR(Bin TL)`)\r\ndoviz_yukumluluk <- as.numeric(df_veri$`P.1-TOPLAM DÖVİZ YÜKÜMLÜLÜKLERİ(Bin TL)`)\r\nkur <- as.numeric(df_veri_2$`(USD) ABD Doları (Döviz Alış)`)\r\n\r\nnet_rezerv <- (dis_varliklar - doviz_yukumluluk) / kur\r\n\r\n\r\n\r\nNet Rezerv = -2247086 ya da -2,2 milyar dolar.\r\nSwaplar\r\n\r\n\r\n\r\nSwaplar = Döviz Swapları + Altın Swapları\r\nEVDS’deki yeri: Tüm Seriler > Ödemeler Dengesi, Uluslararası\r\nYatırım Pozisyonu > Uluslararası Rezervler ve Döviz Likiditesi\r\nTablosu (Milyon ABD Doları)\r\nWeb Servis ile almak için:\r\nÖDEMELER DENGESİ, ULUSLARARASI YATIRIM POZİSYONU’nun bulunduğu\r\nkategorinin ID’si 18’dir. Bunun yanında Uluslararası Rezervler ve Döviz\r\nLikiditesi Tablosu (Milyon ABD Doları)’nın veri grubu kodu\r\nbie_ulusdovlkd; II.2. Yurt içi para karşılığında döviz forward ve\r\nfuture’ların toplam kısa ve fazla pozisyon büyüklükleri (para\r\nswaplarının gelecekteki bacağını da kapsar.) (Milyon ABD Doları)’nın ve\r\nII.3. Diğer (Milyon ABD Doları)’nın seri kodları sırasıyla\r\nTP.DOVVARNC.K14 ve TP.DOVVARNC.K23’tür.\r\n\r\n\r\nkategori_id_3 <- df_kategori %>% \r\n  filter(TOPIC_TITLE_TR == 'ÖDEMELER DENGESİ, ULUSLARARASI YATIRIM POZİSYONU') %>% \r\n  pull(CATEGORY_ID)\r\n\r\ndf_verigrubu_3 <- fromJSON(url_verigrubu) %>% \r\n  as.data.frame() %>% \r\n  filter(CATEGORY_ID == kategori_id_3) %>% \r\n  select(CATEGORY_ID,\r\n         DATAGROUP_CODE,\r\n         DATAGROUP_NAME,\r\n         FREQUENCY_STR,\r\n         NOTE,\r\n         START_DATE,\r\n         END_DATE)\r\n\r\nverigrubu_kodu_3 <- df_verigrubu_3 %>% \r\n  filter(DATAGROUP_NAME == 'Uluslararası Rezervler ve Döviz Likiditesi Tablosu (Milyon ABD Doları)') %>% \r\n  pull(DATAGROUP_CODE)\r\n\r\nurl_seri_3 <- paste0(\"https://evds2.tcmb.gov.tr/service/evds/serieList/key=\",\r\n                     api_key,\r\n                     \"&type=json&code=\",\r\n                     verigrubu_kodu_3)\r\n\r\ndf_seri_3 <- fromJSON(url_seri_3) %>% \r\n  as.data.frame() %>% \r\n  select(SERIE_CODE,\r\n         DATAGROUP_CODE,\r\n         SERIE_NAME,\r\n         FREQUENCY_STR,\r\n         DEFAULT_AGG_METHOD_STR,\r\n         DEFAULT_AGG_METHOD,\r\n         START_DATE,\r\n         END_DATE)\r\n\r\nuzun_vektor <- paste0(\r\n  \"II.2. Yurt içi para karşılığında döviz forward ve future'ların \",\r\n  \"toplam kısa ve fazla pozisyon büyüklükleri \",\r\n  \"(para swaplarının gelecekteki bacağını da kapsar.) (Milyon ABD Doları)\"\r\n)\r\n\r\nseri_3 <- df_seri_3 %>% \r\n  filter(SERIE_NAME %in% c(uzun_vektor,\r\n                           'II.3. Diğer (Milyon ABD Doları)')) %>% \r\n  pull(SERIE_CODE)\r\n\r\naylikTarih <- \"01-02-2021\"\r\nfrekans_2 <- 5\r\n\r\nurl_veri_3 <- paste0(\"https://evds2.tcmb.gov.tr/service/evds/series=\",\r\n                     seri_3[1],\r\n                     \"-\",\r\n                     seri_3[2],\r\n                     \"&startDate=\",\r\n                     aylikTarih,\r\n                     \"&endDate=\",\r\n                     aylikTarih,\r\n                     \"&frequency=\",\r\n                     frekans_2,\r\n                     \"&type=json&key=\",\r\n                     api_key)\r\n\r\ndf_veri_3 <- fromJSON(url_veri_3) %>% \r\n  as.data.frame() %>% \r\n  select(2,3,4) %>% \r\n  rename(\r\n    \"Tarih\"=1,\r\n    \"II.2. Yurt içi para karşılığında...\"=2,\r\n    \"II.3. Diğer (Milyon ABD Doları)\"=3\r\n  )\r\n\r\n\r\n\r\nYukarıda veriyi aylık olarak çekeceğimiz için frekansı 5 ve tarihi\r\nbaşında 1 olacak şekilde yazdık.\r\nSwap tutarını aşağıdaki gibi hesaplayabiliriz.\r\n\r\n\r\n# Birimler Milyon ABD Dolarıdır.\r\n\r\ndoviz_swap <- as.numeric(df_veri_3$`II.2. Yurt içi para karşılığında...`)\r\naltin_swap <- as.numeric(df_veri_3$`II.3. Diğer (Milyon ABD Doları)`)\r\n\r\nswap <- doviz_swap + altin_swap\r\n\r\n\r\n\r\nSwap tutarı = -58024 ya da -58,1 milyar dolar.\r\nSwap Hariç Net Rezervler\r\nSwap Hariç Net Rezervler = Net Rezervler - Swaplar\r\n\r\n\r\nrezerv <- net_rezerv + swap*1000 #birim farklılığı giderildi.\r\n\r\n\r\n\r\nNet rezervler (-) olduğu ve swaplar ile yükümlülüğümüz arttığı için\r\niki değeri topluyoruz.\r\nSwap hariç net rezervler -60271086 ya da -60,3 milyar dolardır.\r\nSon olarak, yazdıklarımızı bir fonksiyonda toplayalım ve güncel\r\nrezerv miktarımızı hesaplayalım.\r\n\r\n\r\nrezerv_hesapla <- function(api_key = NULL, haftalikTarih = NULL, aylikTarih = NULL){\r\n  \r\n  # Net Rezerv\r\n  \r\n  url_veri <- paste0(\"https://evds2.tcmb.gov.tr/service/evds/series=\",\r\n                     \"TP.AB.A02-TP.AB.A10\",\r\n                     \"&startDate=\",\r\n                     haftalikTarih,\r\n                     \"&endDate=\",\r\n                     haftalikTarih,\r\n                     \"frequency=3\",\r\n                     \"&type=json&key=\",\r\n                     api_key)\r\n  \r\n  df_veri <- fromJSON(url_veri) %>% \r\n    as.data.frame() %>% \r\n    select(2,3,4) %>% \r\n    rename(\r\n      \"Tarih\"=1,\r\n      \"A.1-DIŞ VARLIKLAR(Bin TL)\"=2,\r\n      \"P.1-TOPLAM DÖVİZ YÜKÜMLÜLÜKLERİ(Bin TL)\"=3\r\n    )\r\n  \r\n  url_veri_2 <- paste0(\"https://evds2.tcmb.gov.tr/service/evds/series=\",\r\n                       \"TP.DK.USD.A.YTL\",\r\n                       \"&startDate=\",\r\n                       haftalikTarih,\r\n                       \"&endDate=\",\r\n                       haftalikTarih,\r\n                       \"&type=json&key=\",\r\n                       api_key)\r\n  \r\n  df_veri_2 <- fromJSON(url_veri_2) %>% \r\n    as.data.frame() %>% \r\n    select(2,3) %>% \r\n    rename(\r\n      \"Tarih\"=1,\r\n      \"(USD) ABD Doları (Döviz Alış)\"=2\r\n    )\r\n  \r\n  dis_varliklar <- as.numeric(df_veri$`A.1-DIŞ VARLIKLAR(Bin TL)`)\r\n  doviz_yukumluluk <- as.numeric(df_veri$`P.1-TOPLAM DÖVİZ YÜKÜMLÜLÜKLERİ(Bin TL)`)\r\n  kur <- as.numeric(df_veri_2$`(USD) ABD Doları (Döviz Alış)`)\r\n  \r\n  net_rezerv <- (dis_varliklar - doviz_yukumluluk) / kur\r\n  \r\n  # Swap\r\n  \r\n  url_veri_3 <- paste0(\"https://evds2.tcmb.gov.tr/service/evds/series=\",\r\n                       \"TP.DOVVARNC.K14-TP.DOVVARNC.K23\",\r\n                       \"&startDate=\",\r\n                       aylikTarih,\r\n                       \"&endDate=\",\r\n                       aylikTarih,\r\n                       \"&frequency=5\",\r\n                       \"&type=json&key=\",\r\n                       api_key)\r\n  \r\n  df_veri_3 <- fromJSON(url_veri_3) %>% \r\n    as.data.frame() %>% \r\n    select(2,3,4) %>% \r\n    rename(\r\n      \"Tarih\"=1,\r\n      \"II.2. Yurt içi para karşılığında...\"=2,\r\n      \"II.3. Diğer (Milyon ABD Doları)\"=3\r\n    )\r\n  \r\n  doviz_swap <- as.numeric(df_veri_3$`II.2. Yurt içi para karşılığında...`)\r\n  altin_swap <- as.numeric(df_veri_3$`II.3. Diğer (Milyon ABD Doları)`)\r\n  \r\n  swap <- doviz_swap + altin_swap\r\n  \r\n  # Swap Hariç Net Rezerv\r\n  \r\n  rezerv <- net_rezerv + swap*1000\r\n  \r\n  return(rezerv)\r\n  \r\n}\r\n\r\nrezerv_hesapla(api_key = \"api_anahtariniz\",\r\n               haftalikTarih = \"28-04-2022\",\r\n               aylikTarih = \"01-03-2022\")\r\n\r\n\r\n\r\nFonksiyonun sonucu her ne kadar önceki örnek ile bir çıksa da yine de\r\ngünceli kontrol edelim.\r\nElimizdeki son haftalık veriler 28 Nisan 2022’ye; çekebildiğimiz swap\r\nverileri ise Mart 2022’ye ait.\r\nNet Rezervler = (1639818009 / 14.7962) - (1548217098 / 14.7962) =\r\n(1639818009 - 1548217098) / 14.7962 = 6190840 ya da 6,2 milyar dolar\r\nSwaplar = (-58373) + (-3768) = -62141 ya da -62,1 milyar dolar\r\nSwap Hariç Net Rezervler = 6,2 + (-62,1) = -55,9 milyar dolar\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-05-04-post2/img1.PNG",
    "last_modified": "2022-05-22T19:21:55+03:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-05-02-post1/",
    "title": "Event Study (Olay Çalışması): FED ve Gezi'nin Kısa Vadede Kura Etkisi",
    "description": "#GeziyiSavunacağız",
    "author": [
      {
        "name": "A. Uraz Akgül",
        "url": {}
      }
    ],
    "date": "2022-05-02",
    "categories": [
      "Finance"
    ],
    "contents": "\r\n\r\n\r\n\r\n\r\n\r\n\r\nGezi’nin 9. yıldönümü yaklaşırken ‘kurun Gezi nedeniyle arttığı’\r\nsözleri duyulmaya başlandı ki bu da devam edecektir. Ben de blogumun ilk\r\nyazısında bu konuya bilimsel bir bakış açısı katmak\r\nistedim.\r\nNormal şartlarda bu konuyu incelemek kolay olabilirdi ancak Gezi’nin\r\nbaşladığı 28 Mayıs gününden önce 22 Mayıs’ta FED’in açıklamaları\r\ngelişmekte olan ülke piyasaları için kritikti. Dönemin FED Başkanı Ben\r\nBernanke Merkez Bankası’nın tahvil alımlarını azaltabileceğini\r\nsöylemişti. Bu da parasal genişlemeden (Quantitative Easing, QE) çıkışın\r\nilk adımıydı.\r\nGezi’nin FED’in açıklamasına yakın bir tarihte başlaması işleri biraz\r\nzorlaştırıyor. Bu tip durumlarda Türkiye ile benzer ülkeleri de\r\nçalışmaya katmak faydalı olabilir. Bunu göz önüne alarak iki grup ülkeyi\r\nçalışmaya dahil ettim: Kırılgan Beşli (Fragile Five) ve Zordaki Onlu\r\n(Troubled Ten).\r\nKırılgan Beşli ülkeleri (Morgan Stanley, 2013): Brezilya, Endonezya,\r\nGüney Afrika, Hindistan ve Türkiye.\r\nZordaki Onlu ülkeleri (Morgan Stanley, 2015): Brezilya, Güney Afrika,\r\nGüney Kore, Kolombiya, Peru, Rusya, Singapur, Şili, Tayland ve\r\nTayvan.\r\nİki grubu birleştirirsek çalışmaya toplamda 13 ülkeyi dahil etmiş\r\nolacağız.\r\nTartışmalar dolar üzerinden ilerlediği için Türkiye de dahil 13\r\nülkenin para birimlerinin dolar karşısındaki değeri baz alındı. Değerler\r\nReuters’tan alınmıştır. Verilere (post1.xlsx) GitHub\r\nhesabımdan ulaşabilirsiniz.\r\n\r\n\r\nÜlke\r\n\r\n\r\nDöviz Kodu\r\n\r\n\r\nBrezilya\r\n\r\n\r\nUSDBRL\r\n\r\n\r\nEndonezya\r\n\r\n\r\nUSDIDR\r\n\r\n\r\nGüney Afrika\r\n\r\n\r\nUSDZAR\r\n\r\n\r\nGüney Kore\r\n\r\n\r\nUSDKRW\r\n\r\n\r\nHindistan\r\n\r\n\r\nUSDINR\r\n\r\n\r\nKolombiya\r\n\r\n\r\nUSDCOP\r\n\r\n\r\nPeru\r\n\r\n\r\nUSDPEN\r\n\r\n\r\nRusya\r\n\r\n\r\nUSDRUB\r\n\r\n\r\nSingapur\r\n\r\n\r\nUSDSGD\r\n\r\n\r\nŞili\r\n\r\n\r\nUSDCLP\r\n\r\n\r\nTayland\r\n\r\n\r\nUSDTHB\r\n\r\n\r\nTayvan\r\n\r\n\r\nUSDTWD\r\n\r\n\r\nTürkiye\r\n\r\n\r\nUSDTRY\r\n\r\n\r\nÖncelikle ülkelerin performanslarına bakalım. 2013 yılının başından\r\nsonuna kadar bir aralık belirledim ve her bir ülke kurunu 100 ile\r\nbaşlatarak bir endeks oluşturdum. Tüm kurların yer aldığı görsel\r\naşağıdaki gibidir.\r\n\r\n\r\n\r\nYukarıdaki grafiğe bir de ayrı ayrı bakalım.\r\n\r\n\r\n\r\n22 Mayıs 2013 tarihi baz alındığında genel resimde bir\r\nhareketlenmenin yaşandığını söyleyebiliriz ancak tam olarak yeterli ve\r\ngüvenilir bir yorum olmayacaktır. Bu noktada son bir görsel ile olay\r\nçalışmasına geçebiliriz. Aşağıdaki görselde 13 ülkenin endeks\r\nortalamasının USDTRY ile olan ilişkisi zaman serisi olarak\r\nverilmiştir.\r\n\r\n\r\n\r\nYukarıdaki görsel, yoruma diğerlerine göre biraz daha kolaylık\r\nkatıyor. Hareketlenmenin 22 Mayıs 2013 öncesinde başladığını ve diğer\r\nEM’ler ile korele bir şekilde hareket ettiğimizi görebiliriz. Kur ile\r\nendeks arasındaki farkı (USDTRY - Endeks > 0, pozitif bölge) ise\r\naşağıdaki gibi verebiliriz.\r\n\r\n\r\n\r\nYazının bundan sonraki kısmında Event Study’e geçebiliriz.\r\nOlay çalışması da diyebileceğimiz Event Study için kısaca herhangi\r\nbir olayın finansal piyasalar üzerine etkisini tespit etmek için\r\nkullanılan istatistiksel bir yöntemdir tanımını yapabiliriz. Literatüre\r\nbakıldığında yapılan çalışmaların hisse/borsa ağırlıklı olduğunu\r\ngörebiliriz. Ancak bu çalışmada yazının başında da belirttiğim nedenden\r\ndolayı ülke kurları üzerinden gitmeyi tercih ettim.\r\nOlay çalışmasını üç parçada inceliyoruz.\r\nEvent Studies in Economics and Finance,\r\nA. Craig MacKinlayEstimation Window denilen Tahmin Penceresi.\r\nTahmin penceresinde ortada henüz bir olay yoktur. Bu adımda USDTRY\r\ngetirilerinin piyasa (13 ülke kurundan hesaplanan endeks) getirisine\r\nkıyasla gerçekleşen normal davranışı belirlenir. Tahmin penceresinde\r\npiyasaya göre düzeltilmiş getiri (market adjusted return) yöntemini\r\nkullanacağız. Aslında bu nedenle tahmin penceresi bölümüne ihtiyacımız\r\nolmayacak (diğer bazı yöntemlerde olabiliyor).\r\n\\(AR_{it} = R_{it} - R_{mt}\\)\r\n\\(AR_{it}:\\) t gününe ait anormal\r\ngetiri (AR: Abnormal Return)\r\n\\(R_{it}:\\) t gününe ait USDTRY\r\ngetirisi\r\n\\(R_{mt}:\\) t gününe ait endeks\r\ngetirisi\r\nTahmin penceresi için bir başlangıç ve bir bitiş tarihi vardır.\r\nEvent Window denilen Olay Penceresi.\r\nOlay penceresi olaydan sonraki aralığı ifade ediyor. İlgili olayın\r\nolduktan sonra kaç gün daha USDTRY üzerinde etkisinin olduğu\r\ngösterilir.\r\nOlay penceresinde tıpkı tahmin penceresinde olduğu gibi bir başlangıç\r\nve bir de bitiş tarihi olmak ile beraber bir de olay günü vardır.\r\nPostevent Window denilen Olay Sonrası Pencere.\r\nOlay sonrası pencerede ise USDTRY’nin uzun vadeli performansı\r\ngösterilir.\r\nOlay sonrası pencerede de diğer iki pencerede olduğu gibi bir\r\nbaşlangıç ve bir de bitiş tarihi vardır.\r\nOlay çalışması ile FED ve Gezi’nin herhangi bir anormal getiriye yol\r\naçıp açmadığı inceleyeceğiz.\r\nAdım adım neler yapacağız?\r\nUSDTRY ve EM endeksinin getirilerini hesaplayarak başlıyoruz. Bunun\r\niçin logaritmik getiriyi kullanacağız.\r\n\r\n\r\n\r\n\r\n\r\n\r\nUSDTRY getirilerinden hesaplanan EM endeks getirilerini çıkarıyoruz\r\nve anormal getirileri (abnormal return) elde ediyoruz.\r\n\r\n\r\n\r\nBir önceki adımda hesaplanan anormal getirilerden kümülatif anormal\r\ngetirileri (cumulative abnormal return) hesaplıyoruz. Anormal getiri\r\ndeğerlerini günlük olarak hesapladık ve bu da piyasanın tepkisini tek\r\nbir gün için ölçer. Uzun dönemdeki olay etkisine bakabilmek için olay\r\npenceresi süresindeki anormal getiriler toplanarak kümülatif anormal\r\ngetiri değerleri hesaplanır. Bu da piyasanın olay penceresi dönemindeki\r\ngenel fiyat eğilimini gösterir.\r\n\r\n\r\n\r\nÇalışmada, FED için olay penceresi, -5 gün olay öncesi, +5 gün\r\nolay sonrası ve olay günü olmak üzere 11 gün olarak; Gezi için (Gezi’nin\r\n31 Mayıs’ta aktif olduğunu göz önüne alırsak) olay penceresi, -5 gün\r\nolay öncesi, +5 gün olay sonrası ve olay günü olmak üzere 11 gün olarak\r\nbelirlenmiştir.\r\nHesapladığımız kümülatif anormal getiri değerleri istatistiksel\r\nolarak sıfırdan farklı ise ilgili olayın değişkenler üzerinde etkili\r\nolduğunu ve anormal değişimi ortaya çıkardığını söyleyeceğiz. Ancak,\r\nelde edilen kümülatif anormal getiri 0’a eşit ya da 0’a çok yakın\r\ndeğerler alıyorsa ilgili olayın değişkenler üzerinde etkili olmadığı\r\nifade edebileceğiz.\r\nTeste karar vermek için öncelikle getirilerin normal dağılıp\r\ndağılmadığını inceleyeceğiz. Normallik varsayımının kontrolü için\r\nShapiro-Wilk normallik testi kullanılmıştır. Çünkü örnek büyüklüğünün\r\n50’den küçük olması durumunda Shapiro-Wilk; büyük olması durumunda ise\r\nKolmogorov Smirnov kullanılır gibi bir kullanım algoritması vardır.\r\nOlay penceresi FED(-5,+5) için;\r\n\\(H_0:\\) Olay penceresi içerisinde,\r\nolay gününden 5 gün öncesi ve 5 gün sonrası kümülatif aşırı getiriler\r\nnormal dağılım göstermektedir.\r\n\\(H_1:\\) Olay penceresi içerisinde,\r\nolay gününden 5 gün öncesi ve 5 gün sonrası kümülatif aşırı getiriler\r\nnormal dağılım göstermemektedir.\r\n\r\n\r\n    Shapiro-Wilk normality test\r\n\r\ndata:  obs_fed\r\nW = 0.89606, p-value = 0.1654\r\n\r\nOlay penceresi Gezi(-5,+5) için;\r\n\\(H_0:\\) Olay penceresi içerisinde,\r\nolay gününden 5 gün öncesi ve 5 gün sonrası kümülatif aşırı getiriler\r\nnormal dağılım göstermektedir.\r\n\\(H_1:\\) Olay penceresi içerisinde,\r\nolay gününden 5 gün öncesi ve 5 gün sonrası kümülatif aşırı getiriler\r\nnormal dağılım göstermemektedir.\r\n\r\n\r\n    Shapiro-Wilk normality test\r\n\r\ndata:  obs_gezi\r\nW = 0.85286, p-value = 0.0465\r\n\r\nShapiro-Wilk testine göre p değerleri sırasıyla 0.1653741 ve 0.046503\r\n%5’ten büyük çıktığı için (ikincisi yaklaşık %5) normallik varsayımının\r\nsağlandığını söyleyebiliriz. Bu durumda parametrik olmayan testler\r\ngrubundaki bağımlı örneklem t testi (Paired Samples T-test) ile bir\r\ngrubun belirli bir olaydan önceki ve sonraki ortalamaları arasındaki\r\nfarkın anlamlılığı test edilebilir.\r\nOlay penceresi FED(-5,+5) için;\r\n\\(H_{0,(\\pm5)}: CAR_{-5} =\r\nCAR_{+5}\\)\r\nOlay günü tarihinden önceki 5 günlük kümülatif ortalama anormal\r\ngetirileriyle olay gününden sonraki 5 günlük kümülatif anormal\r\ngetirileri arasında fark yoktur.\r\n\\(H_{1,(\\pm5)}: CAR_{-5} \\neq\r\nCAR_{+5}\\)\r\nOlay günü tarihinden önceki 5 günlük kümülatif ortalama anormal\r\ngetirileriyle olay gününden sonraki 5 günlük kümülatif anormal\r\ngetirileri arasında fark vardır.\r\n\r\n\r\n    Paired t-test\r\n\r\ndata:  before_fed and after_fed\r\nt = 1.5718, df = 4, p-value = 0.1911\r\nalternative hypothesis: true difference in means is not equal to 0\r\n95 percent confidence interval:\r\n -0.002125328  0.007671368\r\nsample estimates:\r\nmean of the differences \r\n             0.00277302 \r\n\r\nOlay penceresi Gezi(-5,+5) için;\r\n\\(H_{0,(\\pm5)}: CAR_{-5} =\r\nCAR_{+5}\\)\r\nOlay günü tarihinden önceki 5 günlük kümülatif ortalama anormal\r\ngetirileriyle olay gününden sonraki 5 günlük kümülatif anormal\r\ngetirileri arasında fark yoktur.\r\n\\(H_{1,(\\pm5)}: CAR_{-5} \\neq\r\nCAR_{+5}\\)\r\nOlay günü tarihinden önceki 5 günlük kümülatif ortalama anormal\r\ngetirileriyle olay gününden sonraki 5 günlük kümülatif anormal\r\ngetirileri arasında fark vardır.\r\n\r\n\r\n    Paired t-test\r\n\r\ndata:  before_gezi and after_gezi\r\nt = -2.2407, df = 4, p-value = 0.08855\r\nalternative hypothesis: true difference in means is not equal to 0\r\n95 percent confidence interval:\r\n -0.012374046  0.001321203\r\nsample estimates:\r\nmean of the differences \r\n           -0.005526422 \r\n\r\np değerleri olay penceresi FED(-5,+5) için 0.1911003 ve Gezi(-5,+5)\r\niçin 0.0885484 %5’ten büyük olduğu için sıfır hipotezi reddedilemez; bu\r\nda olay öncesi ile sonrası ortalama getirilerinde fark olmadığını\r\ngösterir.\r\nOrtalama getiriler FED(-5,+5) için olay öncesi 0.0039657 iken; olay\r\nsonrası 0.0011927; Gezi(-5,+5) için olay öncesi -0.0013321 iken; olay\r\nsonrası 0.0041943 olmuştur.\r\nBir de kümülatif anormal getirilerin istatistiksel olarak anlamlı\r\nolup olmadıklarına bireysel olarak bakalım. Bu durumda t istatistiği\r\n\\(\\frac{CAR}{\\sigma(CAR)*\\sqrt{Gün\\\r\nSayısı}}\\) olacak.\r\nUSING DAILY STOCK RETURNS The Case of\r\nEvent Studies*, S.J.Brown, J.B.Warner\r\n\r\n\r\n\r\n\r\n\r\nFED için olay öncesinde 3 kümülatif anormal getiri istatistiksel\r\nolarak anlamlı çıkarken; Gezi için olay sonrasında 2 kümülatif anormal\r\ngetiri istatistiksel olarak anlamlı çıkmıştır.\r\nOlay penceresi için FED(-5,+5) ve Gezi(-5,+5) demiştik. Bunların\r\nistatistiksel anlamlılığına bakalım.\r\n\r\n\r\n\r\nOlay penceresinde FED(,-5,+5) ve Gezi(-5,+5) için |-0.0389315| >\r\n1.96 ve |-0.1593087| > 1.96 olmadığı için istatistiksel olarak\r\nanlamlı çıkmamıştır.\r\nSonuç olarak şunları söyleyebilirim: Bu çalışma, FED ve Gezi’nin kısa\r\nvadeli etkilerini göstermektedir. Kısa vadede her iki olayda da\r\nistatistiksel olarak anlamlı bir etki olmasa da Türkiye’nin diğer EM’ler\r\nile 22 Mayıs 2013’ten önce başlayarak korele bir şekilde hareket ettiği\r\ndikkate alınmalıdır. Belirlenen olay günlerinin farklı olay\r\npencerelerinde de değerlendirilmesini tavsiye ederim. Ayrıca tercih\r\nettiğim market adjusted returns dışında farklı yöntemlerin de\r\nkullanıldığını hatırlatmak isterim. Daha uzun vadedeki etkilere bakmak\r\niçin farklı istatistiksel yöntemlerin uygulanması yazının başında\r\nbelirtilen tartışmaya farklı bir açı katacaktır.\r\nÇalışmanın R kodlarına aşağıdan ulaşılabilir.\r\n\r\n\r\noptions(scipen = 999)\r\nlibrary(tidyverse)\r\n\r\ndf <- readxl::read_excel(\"data.xlsx\")\r\n\r\nmaster <- df %>% \r\n  mutate(Date = as.Date(Date)) %>% \r\n  filter(Date >= as.Date(\"2013-01-01\") & Date <= as.Date(\"2013-12-31\"))\r\n\r\nemergingMarket <- master %>% \r\n  pivot_longer(!Date, names_to = \"Currencies\", values_to = \"Values\") %>% \r\n  arrange(Currencies)\r\n\r\ninitialValues <- emergingMarket %>% \r\n  group_by(Currencies) %>% \r\n  slice_min(Date) %>% \r\n  rename(\"Initial\"=3)\r\n\r\nemergingMarketFinal <- emergingMarket %>% \r\n  left_join(initialValues, by = c(\"Date\",\"Currencies\")) %>% \r\n  mutate(Initial = zoo::na.locf(Initial)) %>% \r\n  mutate(\"SubIndex\" = Values / Initial * 100) %>% \r\n  mutate(\"ColGr\" = ifelse(Currencies == \"USDTRY\", \"USDTRY\", \"Diğer EM'ler\"))\r\n\r\nggplot(emergingMarketFinal,\r\n       aes(x = Date, y = SubIndex, group = Currencies, color = ColGr)) +\r\n  geom_line() +\r\n  geom_hline(yintercept = 100) +\r\n  geom_vline(xintercept = as.Date(\"2013-05-22\"), linetype = \"dashed\") +\r\n  theme_minimal() +\r\n  theme(legend.title = element_blank(),\r\n        legend.position = \"bottom\",\r\n        axis.title = element_blank(),\r\n        plot.caption = element_text(face = \"italic\")) +\r\n  scale_color_manual(values = c(\"gray80\",\"red\")) +\r\n  labs(caption = \"EM: Emerging Market\")\r\n\r\nggplot(emergingMarketFinal,\r\n       aes(x = Date, y = SubIndex, group = Currencies, color = ColGr)) +\r\n  geom_line() +\r\n  geom_hline(yintercept = 100) +\r\n  geom_vline(xintercept = as.Date(\"2013-05-22\"), linetype = \"dashed\") +\r\n  theme_minimal() +\r\n  theme(legend.title = element_blank(),\r\n        legend.position = \"none\",\r\n        axis.title = element_blank(),\r\n        strip.text = element_text(size = 20)) +\r\n  scale_color_manual(values = c(\"gray30\",\"red\")) +\r\n  scale_x_date(date_labels = \"%m-%Y\") +\r\n  facet_wrap(~Currencies, ncol = 3)\r\n\r\nemIndex <- emergingMarketFinal %>% \r\n  select(Date,Currencies,SubIndex) %>% \r\n  pivot_wider(names_from = \"Currencies\", values_from = \"SubIndex\") %>% \r\n  mutate(\"EMIndex\" = rowMeans(.[,-1], na.rm = TRUE))\r\n\r\nemIndex %>% \r\n  select(Date,USDTRY,EMIndex) %>% \r\n  pivot_longer(!Date, names_to = \"Currencies\", values_to = \"Index\") %>% \r\n  ggplot(aes(x = Date, y = Index, group = Currencies, color = Currencies)) +\r\n  geom_line() +\r\n  geom_hline(yintercept = 100) +\r\n  geom_vline(xintercept = as.Date(\"2013-05-22\"), linetype = \"dashed\") +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        legend.title = element_blank(),\r\n        legend.position = \"bottom\",\r\n        plot.caption = element_text(face = \"italic\")) +\r\n  scale_color_manual(values = c(\"gray30\",\"red\")) +\r\n  labs(caption = \"EMIndex: 13 Emerging Market'ın Ortalaması\")\r\n\r\nemIndex %>% \r\n  select(Date,USDTRY,EMIndex) %>% \r\n  mutate(Diff = USDTRY - EMIndex) %>% \r\n  ggplot(aes(x = Date, y = Diff)) +\r\n  geom_area(fill = \"gray40\") +\r\n  geom_vline(xintercept = as.Date(\"2013-05-22\"), linetype = \"dashed\") +\r\n  geom_hline(yintercept = 0) +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank())\r\n\r\ndf_event <- emIndex %>% \r\n  select(Date,USDTRY,EMIndex) %>% \r\n  mutate(\r\n    \"USDTRY Return\" = lag(log(lead(USDTRY)/USDTRY)),\r\n    \"EMIndex Return\" = lag(log(lead(EMIndex)/EMIndex))\r\n  ) %>% \r\n  na.omit()\r\n\r\ndf_event %>% \r\n  select(Date,`USDTRY Return`,`EMIndex Return`) %>% \r\n  pivot_longer(!Date, names_to = \"Vars\", values_to = \"Return\") %>% \r\n  ggplot(aes(x = Date, y = Return, group = Vars, color = Vars)) +\r\n  geom_line() +\r\n  geom_vline(xintercept = as.Date(\"2013-05-22\"), linetype = \"dashed\") +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        legend.position = \"none\") +\r\n  facet_wrap(~Vars, ncol = 1) +\r\n  scale_color_manual(values = c(\"blue\",\"red\"))\r\n\r\ndf_event <- df_event %>% \r\n  mutate(\"Abnormal Return\" = `USDTRY Return` - `EMIndex Return`)\r\n\r\n# -5,5 (FED için)\r\n\r\ndf_event_fed <- df_event %>% \r\n  filter(Date >= as.Date(\"2013-05-15\") & Date <= as.Date(\"2013-05-29\")) %>% \r\n  mutate(\"Cumulative Abnormal Return\" = cumsum(`Abnormal Return`))\r\n\r\n# -5,5 (Gezi için)\r\n\r\ndf_event_gezi <- df_event %>% \r\n  filter(Date >= as.Date(\"2013-05-24\") & Date <= as.Date(\"2013-06-07\")) %>% \r\n  mutate(\"Cumulative Abnormal Return\" = cumsum(`Abnormal Return`))\r\n\r\nobs_fed <- df_event_fed %>% \r\n  pull(`Cumulative Abnormal Return`)\r\n\r\nshapiro.test(obs_fed)\r\nshapiro.test(obs_fed)$p.value\r\n\r\nobs_gezi <- df_event_gezi %>% \r\n  pull(`Cumulative Abnormal Return`)\r\n\r\nshapiro.test(obs_gezi)\r\nshapiro.test(obs_gezi)$p.value\r\n\r\nbefore_fed <- df_event_fed %>% \r\n  filter(Date < as.Date(\"2013-05-22\")) %>% \r\n  pull(`Cumulative Abnormal Return`)\r\n\r\nafter_fed <- df_event_fed %>% \r\n  filter(Date > as.Date(\"2013-05-22\")) %>% \r\n  pull(`Cumulative Abnormal Return`)\r\n\r\nt.test(before_fed, after_fed, paired = TRUE)\r\nt.test(before_fed, after_fed, paired = TRUE)$p.value\r\n\r\nbefore_gezi <- df_event_gezi %>% \r\n  filter(Date < as.Date(\"2013-05-31\")) %>% \r\n  pull(`Cumulative Abnormal Return`)\r\n\r\nafter_gezi <- df_event_gezi %>% \r\n  filter(Date > as.Date(\"2013-05-31\")) %>% \r\n  pull(`Cumulative Abnormal Return`)\r\n\r\nt.test(before_gezi, after_gezi, paired = TRUE)\r\nt.test(before_gezi, after_gezi, paired = TRUE)$p.value\r\n\r\nmean(before_fed)\r\nmean(after_fed)\r\n\r\nmean(before_gezi)\r\nmean(after_gezi)\r\n\r\nsigma_fed <- df_event_fed %>% \r\n  summarise(sd = sd(`Abnormal Return`)) %>% \r\n  pull(sd)\r\n\r\ndf_event_fed <- df_event_fed %>% \r\n  mutate(t = seq(-5,5,1)) %>% \r\n  mutate(\"t_stat\" = `Cumulative Abnormal Return`/sigma_fed*sqrt(abs(t))) %>% \r\n  mutate(\"Result\" = ifelse(abs(t_stat) > 1.96, \"SIGNIFICANT\",\"INSIGNIFICANT\"))\r\n\r\ndf_event_fed %>% \r\n  ggplot(aes(x = factor(t), y = `Cumulative Abnormal Return`, group = 1)) +\r\n  geom_line() +\r\n  geom_point(aes(color = Result), size = 7) +\r\n  geom_vline(xintercept = factor(0)) +\r\n  geom_hline(yintercept = 0) +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        legend.title = element_blank(),\r\n        plot.title = element_text(size = 20),\r\n        plot.subtitle = element_text(size = 15)) +\r\n  scale_color_manual(values = c(\"gray40\",\"red\")) +\r\n  labs(title = \"FED\",\r\n       subtitle = \"t0: 22 Mayıs 2013\")\r\n\r\nsigma_gezi <- df_event_gezi %>% \r\n  summarise(sd = sd(`Abnormal Return`)) %>% \r\n  pull(sd)\r\n\r\ndf_event_gezi <- df_event_gezi %>% \r\n  mutate(t = seq(-5,5,1)) %>% \r\n  mutate(\"t_stat\" = `Cumulative Abnormal Return`/sigma_gezi*sqrt(abs(t))) %>% \r\n  mutate(\"Result\" = ifelse(abs(t_stat) > 1.96, \"SIGNIFICANT\",\"INSIGNIFICANT\"))\r\n\r\ndf_event_gezi %>% \r\n  ggplot(aes(x = factor(t), y = `Cumulative Abnormal Return`, group = 1)) +\r\n  geom_line() +\r\n  geom_point(aes(color = Result), size = 7) +\r\n  geom_vline(xintercept = factor(0)) +\r\n  geom_hline(yintercept = 0) +\r\n  theme_minimal() +\r\n  theme(axis.title = element_blank(),\r\n        legend.title = element_blank(),\r\n        plot.title = element_text(size = 20),\r\n        plot.subtitle = element_text(size = 15)) +\r\n  scale_color_manual(values = c(\"gray40\",\"red\")) +\r\n  labs(title = \"GEZİ\",\r\n       subtitle = \"t0: 31 Mayıs 2013\")\r\n\r\new_sum_fed <- sum(df_event_fed$`Abnormal Return`)\r\new_tstat_fed <- ew_sum_fed / (sigma_fed * sqrt(11))\r\n\r\new_sum_gezi <- sum(df_event_gezi$`Abnormal Return`)\r\new_tstat_gezi <- ew_sum_gezi / (sigma_gezi * sqrt(11))\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-05-02-post1/post1_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2022-05-22T19:22:31+03:00",
    "input_file": {}
  }
]
