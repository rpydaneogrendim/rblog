---
title: "Haber Paylaşımı Yapan Twitter Hesaplarının Benzerliği"
description: |
  Haber paylaşımı yapan Twitter hesaplarının kosinüs benzerliği ile ölçülmesi.
author:
  - name: A. Uraz Akgül
date: 2022-06-12
output:
  distill::distill_article:
    self_contained: false
categories:
  - Machine Learning
  - Text
  - Social Media
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Uygulama için belirlemiş olduğum haber paylaşımı yapan 25 adet Twitter hesabının benzerlik sonuçları aşağıdaki gibidir.

```{r echo=FALSE}

knitr::include_graphics("result.png")

```

Twitter hesaplarının benzerliğini ölçmek için atılan tweetleri ve yöntem olarak da kosinüs benzerliğini kullandım.

**Kosinüs Benzerliği**

Kosinüs benzerliği, metinler arasındaki vektörel uzaklığı ölçer. Kosinüs benzerliği yöntemi ile aslında trigonometrideki kosinüs fonksiyonu kullanılıyor. Metinler birer vektör olarak dikkate alınıyor ve iki vektörün birbirleri ile olan açısı ölçülüyor. Bu benzerlik, iki vektörün çarpımının iki vektörün boylarının çarpımına oranı olarak hesaplanır.

$cos(\theta) = \frac{x.y}{||x||||y||} = \frac{\sum_{i=1}^{n}x_iy_i}{\sqrt{\sum_{i=1}^{n}x_i^2}\sqrt{\sum_{i=1}^{n}y_i^2}}$

Basit bir örnek ile nasıl hesaplandığına bakalım.

```{r}

x <- c(3,4,1,0)
y <- c(3,4,4,8)

```

$x.y = 3*3 + 4*4 + 1*4 + 0*8 = 29$

$||x|| = \sqrt{3^2 + 4^2 + 1^2 + 0^2} = 5.09902$

$||y|| = \sqrt{3^2 + 4^2 + 4^2 + 8^2} = 10.24695$

$cos(x,y) = cos(\theta) = \frac{29}{5.09902*10.24695} = 0.5550303$

Kosinüs açısı 0 olursa ($cos(\theta) = 0$), iki vektör arasında tam benzerlik vardır ($cos(0) = 1$).

Kosinüs açısı 90 olursa ($cos(\theta) = 90$), iki vektör arasında benzerlik yoktur ($cos(90) = 0$).

Manuel yapmak yerine R'da *lsa* paketi yardımıyla da kosinüs benzerliği bulunabilir.

```{r}

as.numeric(lsa::cosine(x,y))

```

Peki, metinlerde bu benzerlik nasıl hesaplanıyor? Kısa cevabı kelime frekansları ile. Bir örnek ile inceleyelim.

```{r}

text1 <- "R programlama dilini öğreniyorum"
text2 <- "Python programalama dilini öğreniyorum"

```

Yukarıdaki örnekte *dilini, öğreniyorum, programlama* kelimeleri ortak; Python ve R kelimeleri farklıdır. Kelime frekanslarını birbirine denk gelecek şekilde yazarsak;

```{r}

# dilini, öğreniyorum, programlama, Python, R

text1_n <- c(1,1,1,0,1)
text2_n <- c(1,1,1,1,0)

as.numeric(lsa::cosine(text1_n,text2_n))

```

Görüldüğü üzere kosinüs benzerliği 0.75 ya da 75% çıkmıştır.

**Uygulama**

25 adet Twitter hesabına ait tweetlere (*post12.xlsx*) [GitHub hesabımdan](https://github.com/rpydaneogrendim/rblog/tree/main/data) ulaşabilirsiniz. İlgili veri setinde sadece hesap adı ve atılan tweetler bulunmaktadır. Retweetler ise çıkarılmıştır.

```{r}

accounts <- c(
  "@Ahaber",
  "@Haberturk",
  "@ntv",
  "@cnnturk",
  "@BirGun_Gazetesi",
  "@t24comtr",
  "@cumhuriyetgzt",
  "@yeniakit",
  "@yenisafak",
  "@Sabah",
  "@trthaber",
  "@anadoluajansi",
  "@halktvcomtr",
  "@tele1comtr",
  "@bbcturkce",
  "@FOXhaber",
  "@gazetesozcu",
  "@tgrthabertv",
  "@gazeteduvar",
  "@euronews_tr",
  "@sputnik_TR",
  "@dw_turkce",
  "@Hurriyet",
  "@solhaberportali",
  "@DikenComTr"
)

```

Veriler aşağıdaki gibi çekilmiştir.

```{r eval=FALSE}

library(tidyverse)
library(rtweet) # tweet
library(tidytext) # düzenli veri formatı
library(stopwords) # Türkçe stop wordler
library(widyr) # tf-idf, kosinüs benzerliği

df <- data.frame()

for(i in 1:length(accounts)){
  
  # n = Inf ile maksimum tweet sayısı çekilmiştir ki bu da 3250'dir.
  # include_rts parametresi FALSE yapılarak retweetler analiz dışı bırakılmıştır.
  
  timeline <- get_timeline(
    user = accounts[i], n = Inf, include_rts = FALSE
  )
  
  df <- df %>% 
    bind_rows(timeline)
  
  print(paste0(accounts[i]," hesabından ",nrow(timeline)," adet tweet çekildi."))
  
  Sys.sleep(time = 1)
  
}

master <- df %>% 
  select(screen_name,text)

```

Tekrar çalıştırmamak için (73930 satırlık bir veri seti) kaydettiğim veri setini kullanıyorum.

```{r echo=FALSE}

library(tidyverse)
library(rtweet) # tweet
library(tidytext) # düzenli veri formatı
library(stopwords) # Türkçe stop wordler
library(widyr) # tf-idf, kosinüs benzerliği

```

```{r}

master <- readxl::read_excel("tweets.xlsx")

```

Bu veri setinden url'leri (http'li) çıkaracağız.

```{r}

master <- master %>% 
  mutate(text = gsub("http.+","",text))

```

Aynı zamanda, türkçe stop wordleri de çıkarmak faydalı olabilir. Stop wordler etkisiz kelimelerdir. Sık kullanılan kelimeleri de kapsar desek yanlış olmaz sanırım.

```{r}

tr_sw <- stopwords(language = "tr", source = "stopwords-iso")

```

Kosinüs benzerliğini iki yöntemi baz alarak hesaplayacağız: Kelime frekansları ve TF-IDF.

```{r}

master <- master %>% 
  unnest_tokens(output = "word", input = "text") %>% # kelimeler ayıklandı
  filter(!(word %in% tr_sw)) %>% # stop wordler kaldırıldı
  count(word, screen_name) %>% # kelimeler hesaplara göre saydırıldı
  bind_tf_idf(word, screen_name, n) # TF-IDF hesaplandı

```

**Kosinüs Benzerliği - Kelime Frekansları**

Yukarıda da örneğini gördüğümüz üzere bu başlık altında kosinüs benzerliği kelimelerin frekansları kullanılarak bulunmuştur.

```{r}

master_freq <- master %>% 
  pairwise_similarity(screen_name, word, n, upper = FALSE, sort = TRUE) %>% # n seçildi
  mutate(item = paste0(item1,"-",item2), .before = similarity) %>% 
  select(-c(item1,item2)) %>% 
  rename("similarity_freq"=2)

```

**Kosinüs Benzerliği - TF-IDF**

Term Frequency-Inverse Document Frequency'nin kısaltması olan TF-IDF için Terim Frekansı-Ters Doküman Frekansı diyebiliriz. Bu hesaplama, bir kelimenin doküman içerisindeki önemini gösteriyor. TF-IDF, TF ile IDF'in çarpımından oluşuyor.

TF: Kelimenin dokümandaki tekrar sayısının dokümandaki toplam kelime sayısına oranıdır.

IDF: Toplam doküman sayısının seçilen kelimenin geçtiği toplam doküman sayısına oranının logaritmasıdır. İlgili kelimenin diğer dokümanlardaki sıklığının artması DF değerini artırır; IDF değerini azaltır.

$w_{i,j} = tf_{i,j}\ x\ log(\frac{N}{df_i})$

$tf_{i,j}:$ i'nin j'de geçme oranı

$df_i:$ i içeren doküman sayısı

$N:$ Doküman sayısı

Örnek: "çalarsaat" kelimesini inceleyelim. FOXhaber'in 30,402 kelimesi vardır. Seçtiğimiz kelime ise 261 defa geçmiştir. Bu durumda TF değeri 261/30,402 = 0.008584962 olur. 25 adet Twitter hesabı olduğu için 25 adet doküman vardır. Seçtiğimiz kelime sadece 1 dokümanda (~hesapta) geçmektedir. Bu durumda IDF değeri log(25/1) = 3.218876 olur. TF-IDF ise TF ile IDF'in çarpımıydı. Yani, 0.008584962 * 3.218876 = 0.02763393 sonucuna ulaşılır.

```{r}

master_tf_idf <- master %>% 
  pairwise_similarity(screen_name, word, tf_idf, upper = FALSE, sort = TRUE) %>% # tf-idf seçildi
  mutate(item = paste0(item1,"-",item2), .before = similarity) %>% 
  select(-c(item1,item2)) %>% 
  rename("similarity_tf_idf"=2)

```

**Sonuç**

```{r}

df_result <- master_freq %>% 
  inner_join(master_tf_idf, by = "item")

```

```{r preview=TRUE}

ggplot(df_result,
       aes(x = similarity_freq, y = similarity_tf_idf, color  = similarity_freq)) +
  geom_point(alpha = .2, size = 4) +
  ggrepel::geom_text_repel(
    data = df_result %>% 
      arrange(desc(similarity_freq)) %>% 
      slice(c(1:10)),
    aes(label = item), size = 3
  ) +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold", hjust = 0.5),
        plot.caption = element_text(face = "italic"),
        legend.position = "none") +
  scale_color_gradient(low = "orange", high = "red") +
  labs(
    title = "Haber Paylaşımı Yapan Twitter Hesaplarının Benzerliği",
    caption = "Top 10 gösterilmiştir.\nSağ-üst köşeye gittikçe benzerlik artmaktadır.",
    x = "Kelime Frekansları",
    y = "TF-IDF"
  )

```

Listenin tamamına aşağıdan ulaşılabilir. Liste, benzerlik oranı en yüksekten en düşüğe doğru kelime frekansına göre hesaplanan benzerliğe göre sıralanmıştır. En yüksek benzerliğe sahip hesaplar ~81% ile trthaber ve anadoluajansi; en düşük benzerliğe sahip hesaplar ise ~19% ile DikenComTr ve tgrthabertv olmuştur. Kelime frekanslarına göre benzerliğin yanında TF-IDF'i de hesaplamıştık. Buna göre, en yüksek benzerliğe sahip hesaplar ~21% ile Sabah ve yenisafak; en düşük benzerliğe sahip hesaplar ise ~0.15% ile FOXhaber ve DikenComTr olmuştur.

```{r echo=FALSE}

df_result %>% 
  rename(
    "Hesaplar"=1,
    "KelimeFrekansı_Benzerlik"=2,
    "TF-IDF_Benzerlik"=3
  ) %>% 
  kableExtra::kbl() %>% 
  kableExtra::kable_styling()

```

